{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Life Satisfaction with NHS Data: Which Lifestyle factors are most important for LS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website: https://www.cdc.gov/nchs/nhis/documentation/2023-nhis.html\n",
    "\n",
    "Dataset: C:\\Users\\sacar\\OneDrive\\Documents\\Projects\\Predicting MH with NHS Data\\adult23.csv\n",
    "\n",
    "Description: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "df = pd.read_csv(r'C:\\Users\\sacar\\OneDrive\\Documents\\Projects\\Predicting MH with NHS Data\\adult23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29522 entries, 0 to 29521\n",
      "Columns: 647 entries, URBRRL to POVRATTC_A\n",
      "dtypes: float64(442), int64(204), object(1)\n",
      "memory usage: 145.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URBRRL</th>\n",
       "      <th>RATCAT_A</th>\n",
       "      <th>INCTCFLG_A</th>\n",
       "      <th>IMPINCFLG_A</th>\n",
       "      <th>LANGSPECR_A</th>\n",
       "      <th>LANGSOC_A</th>\n",
       "      <th>LANGDOC_A</th>\n",
       "      <th>LANGMED_A</th>\n",
       "      <th>LANGHM_A</th>\n",
       "      <th>PPSU</th>\n",
       "      <th>...</th>\n",
       "      <th>PROXYREL_A</th>\n",
       "      <th>PROXY_A</th>\n",
       "      <th>AVAIL_A</th>\n",
       "      <th>HHSTAT_A</th>\n",
       "      <th>INTV_MON</th>\n",
       "      <th>RECTYPE</th>\n",
       "      <th>IMPNUM_A</th>\n",
       "      <th>WTFA_A</th>\n",
       "      <th>HHX</th>\n",
       "      <th>POVRATTC_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7371.139</td>\n",
       "      <td>H029691</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3146.794</td>\n",
       "      <td>H028812</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 647 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   URBRRL  RATCAT_A  INCTCFLG_A  IMPINCFLG_A  LANGSPECR_A  LANGSOC_A  \\\n",
       "0       3         4           0            0          NaN        NaN   \n",
       "1       4         8           0            0          NaN        NaN   \n",
       "\n",
       "   LANGDOC_A  LANGMED_A  LANGHM_A  PPSU  ...  PROXYREL_A  PROXY_A  AVAIL_A  \\\n",
       "0        NaN        NaN       NaN     2  ...         NaN      NaN        1   \n",
       "1        NaN        NaN       NaN     2  ...         NaN      NaN        1   \n",
       "\n",
       "   HHSTAT_A  INTV_MON  RECTYPE  IMPNUM_A    WTFA_A      HHX  POVRATTC_A  \n",
       "0         1         1       10         1  7371.139  H029691        1.01  \n",
       "1         1         1       10         1  3146.794  H028812        2.49  \n",
       "\n",
       "[2 rows x 647 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URBRRL</th>\n",
       "      <th>RATCAT_A</th>\n",
       "      <th>INCTCFLG_A</th>\n",
       "      <th>IMPINCFLG_A</th>\n",
       "      <th>LANGSPECR_A</th>\n",
       "      <th>LANGSOC_A</th>\n",
       "      <th>LANGDOC_A</th>\n",
       "      <th>LANGMED_A</th>\n",
       "      <th>LANGHM_A</th>\n",
       "      <th>PPSU</th>\n",
       "      <th>...</th>\n",
       "      <th>PHSTAT_A</th>\n",
       "      <th>PROXYREL_A</th>\n",
       "      <th>PROXY_A</th>\n",
       "      <th>AVAIL_A</th>\n",
       "      <th>HHSTAT_A</th>\n",
       "      <th>INTV_MON</th>\n",
       "      <th>RECTYPE</th>\n",
       "      <th>IMPNUM_A</th>\n",
       "      <th>WTFA_A</th>\n",
       "      <th>POVRATTC_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>4049.000000</td>\n",
       "      <td>3973.000000</td>\n",
       "      <td>4049.000000</td>\n",
       "      <td>4049.000000</td>\n",
       "      <td>22104.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.0</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.0</td>\n",
       "      <td>29522.0</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.317119</td>\n",
       "      <td>9.666757</td>\n",
       "      <td>0.041664</td>\n",
       "      <td>0.373721</td>\n",
       "      <td>1.453445</td>\n",
       "      <td>1.480997</td>\n",
       "      <td>1.301309</td>\n",
       "      <td>1.392937</td>\n",
       "      <td>2.063563</td>\n",
       "      <td>31.375246</td>\n",
       "      <td>...</td>\n",
       "      <td>2.460369</td>\n",
       "      <td>1.286778</td>\n",
       "      <td>1.039783</td>\n",
       "      <td>1.205542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.472089</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8747.291918</td>\n",
       "      <td>4.106340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.061522</td>\n",
       "      <td>4.048065</td>\n",
       "      <td>0.199823</td>\n",
       "      <td>0.712244</td>\n",
       "      <td>0.801351</td>\n",
       "      <td>0.790779</td>\n",
       "      <td>0.631127</td>\n",
       "      <td>0.734160</td>\n",
       "      <td>1.287790</td>\n",
       "      <td>29.253976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.074983</td>\n",
       "      <td>0.668921</td>\n",
       "      <td>0.338166</td>\n",
       "      <td>1.087867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.444791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5690.650182</td>\n",
       "      <td>2.961649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1792.441000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4643.531750</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7374.546000</td>\n",
       "      <td>3.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10994.809500</td>\n",
       "      <td>5.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39925.600000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 646 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URBRRL      RATCAT_A    INCTCFLG_A   IMPINCFLG_A  LANGSPECR_A  \\\n",
       "count  29522.000000  29522.000000  29522.000000  29522.000000  4049.000000   \n",
       "mean       2.317119      9.666757      0.041664      0.373721     1.453445   \n",
       "std        1.061522      4.048065      0.199823      0.712244     0.801351   \n",
       "min        1.000000      1.000000      0.000000      0.000000     1.000000   \n",
       "25%        1.000000      7.000000      0.000000      0.000000     1.000000   \n",
       "50%        2.000000     10.000000      0.000000      0.000000     1.000000   \n",
       "75%        3.000000     14.000000      0.000000      0.000000     2.000000   \n",
       "max        4.000000     14.000000      1.000000      2.000000     9.000000   \n",
       "\n",
       "         LANGSOC_A    LANGDOC_A    LANGMED_A      LANGHM_A          PPSU  ...  \\\n",
       "count  3973.000000  4049.000000  4049.000000  22104.000000  29522.000000  ...   \n",
       "mean      1.480997     1.301309     1.392937      2.063563     31.375246  ...   \n",
       "std       0.790779     0.631127     0.734160      1.287790     29.253976  ...   \n",
       "min       1.000000     1.000000     1.000000      1.000000      1.000000  ...   \n",
       "25%       1.000000     1.000000     1.000000      2.000000      8.000000  ...   \n",
       "50%       1.000000     1.000000     1.000000      2.000000     24.000000  ...   \n",
       "75%       2.000000     2.000000     2.000000      2.000000     48.000000  ...   \n",
       "max       9.000000     9.000000     9.000000      9.000000    153.000000  ...   \n",
       "\n",
       "           PHSTAT_A  PROXYREL_A     PROXY_A       AVAIL_A  HHSTAT_A  \\\n",
       "count  29522.000000  537.000000  553.000000  29522.000000   29522.0   \n",
       "mean       2.460369    1.286778    1.039783      1.205542       1.0   \n",
       "std        1.074983    0.668921    0.338166      1.087867       0.0   \n",
       "min        1.000000    1.000000    1.000000      1.000000       1.0   \n",
       "25%        2.000000    1.000000    1.000000      1.000000       1.0   \n",
       "50%        2.000000    1.000000    1.000000      1.000000       1.0   \n",
       "75%        3.000000    1.000000    1.000000      1.000000       1.0   \n",
       "max        9.000000    4.000000    8.000000      8.000000       1.0   \n",
       "\n",
       "           INTV_MON  RECTYPE  IMPNUM_A        WTFA_A    POVRATTC_A  \n",
       "count  29522.000000  29522.0   29522.0  29522.000000  29522.000000  \n",
       "mean       6.472089     10.0       1.0   8747.291918      4.106340  \n",
       "std        3.444791      0.0       0.0   5690.650182      2.961649  \n",
       "min        1.000000     10.0       1.0   1792.441000      0.000000  \n",
       "25%        3.000000     10.0       1.0   4643.531750      1.800000  \n",
       "50%        7.000000     10.0       1.0   7374.546000      3.310000  \n",
       "75%        9.000000     10.0       1.0  10994.809500      5.650000  \n",
       "max       12.000000     10.0       1.0  39925.600000     11.000000  \n",
       "\n",
       "[8 rows x 646 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 29522 entries, 0 to 29521\n",
      "Series name: LSATIS4_A\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "29522 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 230.8 KB\n",
      "None\n",
      "[2 1 3 9 4 7]\n"
     ]
    }
   ],
   "source": [
    "print(df_copy[\"LSATIS4_A\"].info())  # Check column type and non-null values\n",
    "\n",
    "print(df_copy[\"LSATIS4_A\"].unique())  # Show unique values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values - Dropping Columns and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    647.000000\n",
      "mean      52.059685\n",
      "std       42.190768\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%       62.421245\n",
      "75%       93.630174\n",
      "max      100.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate missing value percentages\n",
    "missing_percent = df_copy.isnull().sum() / len(df_copy) * 100\n",
    "\n",
    "# Print summary\n",
    "print(missing_percent.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with missing values: 440\n",
      "Columns with Missing Values:\n",
      "LANGSPECR_A: 25473 missing (86.28%)\n",
      "LANGSOC_A: 25549 missing (86.54%)\n",
      "LANGDOC_A: 25473 missing (86.28%)\n",
      "LANGMED_A: 25473 missing (86.28%)\n",
      "LANGHM_A: 7418 missing (25.13%)\n",
      "SCHDYMSSTC_A: 27881 missing (94.44%)\n",
      "AFNOW: 8099 missing (27.43%)\n",
      "REPWRKDYTC_A: 28193 missing (95.50%)\n",
      "YRSINUS_A: 24820 missing (84.07%)\n",
      "PRTNREDUCP_A: 27652 missing (93.67%)\n",
      "SPOUSEDUCP_A: 17305 missing (58.62%)\n",
      "SASPPRACE_A: 15434 missing (52.28%)\n",
      "SASPPHISP_A: 15434 missing (52.28%)\n",
      "PRTNRAGETC_A: 27651 missing (93.66%)\n",
      "SPOUSAGETC_A: 17305 missing (58.62%)\n",
      "PRTNRWKFT_A: 28118 missing (95.24%)\n",
      "PRTNRWRK_A: 27660 missing (93.69%)\n",
      "SPOUSWKFT_A: 21989 missing (74.48%)\n",
      "SPOUSWRK_A: 17356 missing (58.79%)\n",
      "SPOUSESEX_A: 17306 missing (58.62%)\n",
      "PRTNRSEX_A: 27651 missing (93.66%)\n",
      "INJWRKDYTC_A: 27562 missing (93.36%)\n",
      "NUMINJTC_A: 27562 missing (93.36%)\n",
      "SHINGYEARP_A: 22275 missing (75.45%)\n",
      "HHRESPSA_FLG: 8637 missing (29.26%)\n",
      "EPINUMSEZP_A: 28954 missing (98.08%)\n",
      "EMPDYSMSS3_A: 11722 missing (39.71%)\n",
      "EMPLSTWOR1_A: 17471 missing (59.18%)\n",
      "EMPWRKFT1_A: 13144 missing (44.52%)\n",
      "EMPWKHRS3_A: 13167 missing (44.60%)\n",
      "EMDOCCUPN2_A: 11722 missing (39.71%)\n",
      "EMDOCCUPN1_A: 11722 missing (39.71%)\n",
      "EMDINDSTN2_A: 11722 missing (39.71%)\n",
      "EMDINDSTN1_A: 11722 missing (39.71%)\n",
      "DIBAGETC_A: 26228 missing (88.84%)\n",
      "DIFYRSTC1_A: 26228 missing (88.84%)\n",
      "DIBA1CNMT_A: 26432 missing (89.53%)\n",
      "COVER65_A: 19819 missing (67.13%)\n",
      "COVER_A: 9703 missing (32.87%)\n",
      "EXCHANGE_A: 11454 missing (38.80%)\n",
      "MILSPC1R_A: 27711 missing (93.87%)\n",
      "OGFLG_A: 29522 missing (100.00%)\n",
      "OPFLG_A: 29522 missing (100.00%)\n",
      "CHFLG_A: 29522 missing (100.00%)\n",
      "MAFLG_A: 29470 missing (99.82%)\n",
      "PLNWRKR2_A: 28998 missing (98.23%)\n",
      "PLNWRKR1_A: 11453 missing (38.79%)\n",
      "RSNHIMISS_A: 27533 missing (93.26%)\n",
      "RSNHIJOB_A: 27533 missing (93.26%)\n",
      "MCADVR_A: 24949 missing (84.51%)\n",
      "PRFLG_A: 28875 missing (97.81%)\n",
      "PLEXCHPR1_A: 28875 missing (97.81%)\n",
      "PRPREM1_A: 28875 missing (97.81%)\n",
      "PXCHNG1_A: 28875 missing (97.81%)\n",
      "HICOSTR2_A: 29114 missing (98.62%)\n",
      "HICOSTR1_A: 14963 missing (50.68%)\n",
      "PRPLCOV1_C_A: 29497 missing (99.92%)\n",
      "PRPLCOV2_C_A: 29518 missing (99.99%)\n",
      "PLEXCHOG_A: 29453 missing (99.77%)\n",
      "PLEXCHOP_A: 29355 missing (99.43%)\n",
      "EXCHPR2_A: 28998 missing (98.23%)\n",
      "EXCHPR1_A: 12101 missing (40.99%)\n",
      "MAXEDUCP_A: 78 missing (0.26%)\n",
      "COLRCAGETC_A: 29307 missing (99.27%)\n",
      "HDNCKAGETC_A: 29458 missing (99.78%)\n",
      "OTHERAGETC_A: 29193 missing (98.89%)\n",
      "UTERUAGETC_A: 29415 missing (99.64%)\n",
      "THYROAGETC_A: 29413 missing (99.63%)\n",
      "THROAAGETC_A: 29480 missing (99.86%)\n",
      "STOMAAGETC_A: 29501 missing (99.93%)\n",
      "SKNDKAGETC_A: 29307 missing (99.27%)\n",
      "SKNNMAGETC_A: 28707 missing (97.24%)\n",
      "SKNMAGETC_A: 29180 missing (98.84%)\n",
      "RECTUAGETC_A: 29502 missing (99.93%)\n",
      "PROSTAGETC_A: 29039 missing (98.36%)\n",
      "PANCRAGETC_A: 29502 missing (99.93%)\n",
      "OVARYAGETC_A: 29448 missing (99.75%)\n",
      "MOUTHAGETC_A: 29509 missing (99.96%)\n",
      "MELANAGETC_A: 29329 missing (99.35%)\n",
      "LYMPHAGETC_A: 29415 missing (99.64%)\n",
      "LUNGAGETC_A: 29377 missing (99.51%)\n",
      "LIVERAGETC_A: 29503 missing (99.94%)\n",
      "LEUKEAGETC_A: 29461 missing (99.79%)\n",
      "LARYNAGETC_A: 29513 missing (99.97%)\n",
      "GALLBAGETC_A: 29519 missing (99.99%)\n",
      "ESOPHAGETC_A: 29505 missing (99.94%)\n",
      "COLONAGETC_A: 29327 missing (99.34%)\n",
      "CERVIAGETC_A: 29346 missing (99.40%)\n",
      "BREASAGETC_A: 28769 missing (97.45%)\n",
      "BRAINAGETC_A: 29490 missing (99.89%)\n",
      "BONEAGETC_A: 29501 missing (99.93%)\n",
      "BLOODAGETC_A: 29496 missing (99.91%)\n",
      "BLADDAGETC_A: 29421 missing (99.66%)\n",
      "OTHERCANP_A: 25760 missing (87.26%)\n",
      "COLRCCAN_A: 25760 missing (87.26%)\n",
      "HDNCKCAN_A: 25760 missing (87.26%)\n",
      "UTERUCAN_A: 27376 missing (92.73%)\n",
      "THYROCAN_A: 25760 missing (87.26%)\n",
      "THROACAN_A: 25760 missing (87.26%)\n",
      "STOMACAN_A: 25760 missing (87.26%)\n",
      "SKNDKCAN_A: 25760 missing (87.26%)\n",
      "SKNNMCAN_A: 25760 missing (87.26%)\n",
      "SKNMCAN_A: 25760 missing (87.26%)\n",
      "RECTUCAN_A: 25760 missing (87.26%)\n",
      "PROSTCAN_A: 27906 missing (94.53%)\n",
      "PANCRCAN_A: 25760 missing (87.26%)\n",
      "OVARYCAN_A: 27376 missing (92.73%)\n",
      "MOUTHCAN_A: 25760 missing (87.26%)\n",
      "MELANCAN_A: 25760 missing (87.26%)\n",
      "LYMPHCAN_A: 25760 missing (87.26%)\n",
      "LUNGCAN_A: 25760 missing (87.26%)\n",
      "LIVERCAN_A: 25760 missing (87.26%)\n",
      "LEUKECAN_A: 25760 missing (87.26%)\n",
      "LARYNCAN_A: 25760 missing (87.26%)\n",
      "GALLBCAN_A: 25760 missing (87.26%)\n",
      "ESOPHCAN_A: 25760 missing (87.26%)\n",
      "COLONCAN_A: 25760 missing (87.26%)\n",
      "CERVICAN_A: 27376 missing (92.73%)\n",
      "BREASCAN_A: 25760 missing (87.26%)\n",
      "BRAINCAN_A: 25760 missing (87.26%)\n",
      "BONECAN_A: 25760 missing (87.26%)\n",
      "BLOODCAN_A: 25760 missing (87.26%)\n",
      "BLADDCAN_A: 25760 missing (87.26%)\n",
      "AGE65: 29400 missing (99.59%)\n",
      "MENTHOLC_A: 26922 missing (91.19%)\n",
      "HOUGVASST_A: 21110 missing (71.51%)\n",
      "FDSNEDAYS_A: 29146 missing (98.73%)\n",
      "FDSNOTEAT_A: 27632 missing (93.60%)\n",
      "FDSWEIGHT_A: 25433 missing (86.15%)\n",
      "FDSHUNGRY_A: 25433 missing (86.15%)\n",
      "FDSLESS_A: 25433 missing (86.15%)\n",
      "FDSSKIPDYS_A: 28016 missing (94.90%)\n",
      "FDSSKIP_A: 25433 missing (86.15%)\n",
      "FLUNCH12M1_A: 23434 missing (79.38%)\n",
      "FWIC12M_A: 15914 missing (53.91%)\n",
      "FSNAP30D_A: 26172 missing (88.65%)\n",
      "INCOTHR_A: 1446 missing (4.90%)\n",
      "INCRETIRE_A: 1446 missing (4.90%)\n",
      "INCWELF_A: 1446 missing (4.90%)\n",
      "SSISSDIDSB_A: 27030 missing (91.56%)\n",
      "SSISSDIBTH_A: 27030 missing (91.56%)\n",
      "INCSSISSDI_A: 1446 missing (4.90%)\n",
      "INCSSRR_A: 1446 missing (4.90%)\n",
      "CEVOLUN2_A: 8068 missing (27.33%)\n",
      "EMDWRKCAT1_A: 11722 missing (39.71%)\n",
      "EMDSUPER_A: 11722 missing (39.71%)\n",
      "EMPHEALINS_A: 11722 missing (39.71%)\n",
      "EMPSICKLV_A: 11722 missing (39.71%)\n",
      "EMPWHENWRK_A: 17523 missing (59.36%)\n",
      "EMPWHYNOT_A: 17470 missing (59.18%)\n",
      "EMPNOWRK_A: 16906 missing (57.27%)\n",
      "VACAREEV_A: 27931 missing (94.61%)\n",
      "VAHOSP_A: 27002 missing (91.46%)\n",
      "VADISB_A: 27002 missing (91.46%)\n",
      "COMBAT_A: 27473 missing (93.06%)\n",
      "AFVETTRN_A: 27002 missing (91.46%)\n",
      "EVRMARRIED_A: 14142 missing (47.90%)\n",
      "SPOUSEP_A: 28790 missing (97.52%)\n",
      "SPOUSLIV_A: 16562 missing (56.10%)\n",
      "HRJBEXP4HR_A: 26841 missing (90.92%)\n",
      "HRVLDPROT_A: 25769 missing (87.29%)\n",
      "HRFIREPROT_A: 25922 missing (87.81%)\n",
      "HRFIRE12M_A: 18076 missing (61.23%)\n",
      "HRFIRETOTR_A: 18076 missing (61.23%)\n",
      "HRJOBPROT_A: 26782 missing (90.72%)\n",
      "HRLOUDJB12M_A: 21980 missing (74.45%)\n",
      "HRLOUDJBYR_A: 21980 missing (74.45%)\n",
      "HRTINMEDSP_A: 25350 missing (85.87%)\n",
      "HRTINPROB_A: 25350 missing (85.87%)\n",
      "HRTINLNG_A: 25350 missing (85.87%)\n",
      "BFALLTIMES_A: 24432 missing (82.76%)\n",
      "BALDHP_A: 23330 missing (79.03%)\n",
      "BALDPROB_A: 23330 missing (79.03%)\n",
      "HRAIDAQR_A: 27788 missing (94.13%)\n",
      "HRTESTLAST_A: 14221 missing (48.17%)\n",
      "CBALHDNO_A: 23051 missing (78.08%)\n",
      "CBALHDINJ_A: 1905 missing (6.45%)\n",
      "EARINFECT3_A: 27830 missing (94.27%)\n",
      "HRWHISP_A: 1134 missing (3.84%)\n",
      "AVISSADV_A: 23974 missing (81.21%)\n",
      "AVISDEV_A: 23750 missing (80.45%)\n",
      "AVISREH_A: 23750 missing (80.45%)\n",
      "SMOKELSCUR_A: 26587 missing (90.06%)\n",
      "PIPECUR_A: 25459 missing (86.24%)\n",
      "CIGAR30D_A: 21376 missing (72.41%)\n",
      "CIGARCUR_A: 21218 missing (71.87%)\n",
      "ECIGNOW_A: 24488 missing (82.95%)\n",
      "CIG30D_A: 28768 missing (97.45%)\n",
      "SMK30D_A: 28734 missing (97.33%)\n",
      "CIGNOW_A: 27175 missing (92.05%)\n",
      "SMKNOW_A: 19149 missing (64.86%)\n",
      "ARTHPH_A: 21791 missing (73.81%)\n",
      "ARTHWRK_A: 21791 missing (73.81%)\n",
      "ARTHLMT_A: 21791 missing (73.81%)\n",
      "JNTPN_A: 23773 missing (80.53%)\n",
      "JNTSYMP_A: 21791 missing (73.81%)\n",
      "TBIEVAL_A: 28584 missing (96.82%)\n",
      "TBILEAGUE_A: 29386 missing (99.54%)\n",
      "TBISPORT_A: 28584 missing (96.82%)\n",
      "INJREDUCE_A: 27679 missing (93.76%)\n",
      "INJSTOPCHG_A: 27679 missing (93.76%)\n",
      "INJFUTWRK_A: 29005 missing (98.25%)\n",
      "INJSTITCH_A: 28273 missing (95.77%)\n",
      "INJBONES_A: 28273 missing (95.77%)\n",
      "INJHOSP_A: 29267 missing (99.14%)\n",
      "INJER_A: 28873 missing (97.80%)\n",
      "INJSAWDOC_A: 27562 missing (93.36%)\n",
      "INJCHORES_A: 27562 missing (93.36%)\n",
      "INJMVTYPE5_A: 29380 missing (99.52%)\n",
      "INJMVTYPE4_A: 29380 missing (99.52%)\n",
      "INJMVTYPE3_A: 29380 missing (99.52%)\n",
      "INJMVTYPE2_A: 29380 missing (99.52%)\n",
      "INJMVTYPE1_A: 29380 missing (99.52%)\n",
      "INJMOTOR_A: 27562 missing (93.36%)\n",
      "INJFALLWRK_A: 29496 missing (99.91%)\n",
      "INJFALLHOM_A: 29336 missing (99.37%)\n",
      "INJFALL_A: 27562 missing (93.36%)\n",
      "INJSPORTS_A: 27562 missing (93.36%)\n",
      "INJWORK_A: 28360 missing (96.06%)\n",
      "INJHOME_A: 27562 missing (93.36%)\n",
      "INJLIMIT_A: 26512 missing (89.80%)\n",
      "REPWRKCAUS_A: 28193 missing (95.50%)\n",
      "REPREDUCE_A: 28286 missing (95.81%)\n",
      "REPSTOPCHG_A: 28286 missing (95.81%)\n",
      "REPFUTWRK_A: 29261 missing (99.12%)\n",
      "REPSAWDOC_A: 28193 missing (95.50%)\n",
      "REPLIMIT_A: 26824 missing (90.86%)\n",
      "PAITOOTH3M_A: 9675 missing (32.77%)\n",
      "PAIAPG3M_A: 9675 missing (32.77%)\n",
      "PAIHDFC3M_A: 9675 missing (32.77%)\n",
      "PAILLMB3M_A: 9675 missing (32.77%)\n",
      "PAIULMB3M_A: 9675 missing (32.77%)\n",
      "PAIBACK3M_A: 9675 missing (32.77%)\n",
      "PAIAFFM3M_A: 9675 missing (32.77%)\n",
      "PAIWKLM3M_A: 9675 missing (32.77%)\n",
      "PAIAMNT_A: 9675 missing (32.77%)\n",
      "MHTPYNOW_A: 25666 missing (86.94%)\n",
      "MHRX_A: 5730 missing (19.41%)\n",
      "DEPLEVEL_A: 15421 missing (52.24%)\n",
      "ANXLEVEL_A: 8882 missing (30.09%)\n",
      "WRKHLTHFC_A: 2871 missing (9.72%)\n",
      "LIVEHEP_A: 621 missing (2.10%)\n",
      "SHTHEPB1_A: 4753 missing (16.10%)\n",
      "TDAPPREG_A: 29171 missing (98.81%)\n",
      "SHINGRIXFS1_A: 25472 missing (86.28%)\n",
      "SHINGRIXN3_A: 27980 missing (94.78%)\n",
      "SHINGRIX3_A: 27231 missing (92.24%)\n",
      "SHINGWHEN1_A: 28777 missing (97.48%)\n",
      "SHTSHINGL1_A: 11879 missing (40.24%)\n",
      "SHTPNEUNB_A: 20692 missing (70.09%)\n",
      "SHOTTYPE2_A: 6080 missing (20.59%)\n",
      "CVDVAC1Y1_A: 6129 missing (20.76%)\n",
      "CVDVAC1M1_A: 6080 missing (20.59%)\n",
      "SHTCVD19NM1_A: 5992 missing (20.30%)\n",
      "FLUPREG2_A: 29367 missing (99.47%)\n",
      "FLUPREG_A: 29460 missing (99.79%)\n",
      "SHTFLUY_A: 14478 missing (49.04%)\n",
      "SHTFLUM_A: 14467 missing (49.00%)\n",
      "LIVEBIRTH_A: 22807 missing (77.25%)\n",
      "PREGFLUYR_A: 22953 missing (77.75%)\n",
      "FHCANRISK_A: 16780 missing (56.84%)\n",
      "FHOVCANNUM_A: 28380 missing (96.13%)\n",
      "FHOVCANEV_A: 16780 missing (56.84%)\n",
      "FHBCAN50_A: 25496 missing (86.36%)\n",
      "FHBCANNUM_A: 25493 missing (86.35%)\n",
      "FHBCANEV_A: 16780 missing (56.84%)\n",
      "MRIREA_A: 28113 missing (95.23%)\n",
      "MRIWHEN_A: 28113 missing (95.23%)\n",
      "MRIHAD_A: 15424 missing (52.25%)\n",
      "MAMNOT1_A: 24197 missing (81.96%)\n",
      "MAMREASON_A: 18472 missing (62.57%)\n",
      "MAMWHEN_A: 18472 missing (62.57%)\n",
      "MAMEV_A: 15424 missing (52.25%)\n",
      "HYSTEV2_A: 13463 missing (45.60%)\n",
      "CERVICWHEN_A: 16840 missing (57.04%)\n",
      "CERVICEV1_A: 13463 missing (45.60%)\n",
      "PSA5YR1_A: 25110 missing (85.06%)\n",
      "PSAREASON_A: 24978 missing (84.61%)\n",
      "PSAWHEN_A: 24978 missing (84.61%)\n",
      "PSATEST_A: 20039 missing (67.88%)\n",
      "COLTEST6_A: 28561 missing (96.74%)\n",
      "COLTEST5_A: 28561 missing (96.74%)\n",
      "COLTEST4_A: 28561 missing (96.74%)\n",
      "COLTEST3_A: 28561 missing (96.74%)\n",
      "COLTEST2_A: 28561 missing (96.74%)\n",
      "COLTEST1_A: 28561 missing (96.74%)\n",
      "COLPROB1_A: 21824 missing (73.92%)\n",
      "CGUARDWHE1_A: 28102 missing (95.19%)\n",
      "FITCOLG1_A: 28202 missing (95.53%)\n",
      "COLOGUARD1_A: 8514 missing (28.84%)\n",
      "FITHWHEN1_A: 24916 missing (84.40%)\n",
      "FITHEV1_A: 8514 missing (28.84%)\n",
      "CTCOLWHEN1_A: 28785 missing (97.50%)\n",
      "CTCOLEV1_A: 8514 missing (28.84%)\n",
      "SIGWHEN_A: 28331 missing (95.97%)\n",
      "COLSIGWHEN_A: 29475 missing (99.84%)\n",
      "COLREASON1_A: 16670 missing (56.47%)\n",
      "COLWHEN_A: 16670 missing (56.47%)\n",
      "COLORECTYP_A: 16498 missing (55.88%)\n",
      "COLORECTEV_A: 8514 missing (28.84%)\n",
      "DIBA1CLAST_A: 26228 missing (88.84%)\n",
      "DIBLAST1_A: 3294 missing (11.16%)\n",
      "RXDL12M_A: 8097 missing (27.43%)\n",
      "RXLS12M_A: 8097 missing (27.43%)\n",
      "RXSK12M_A: 8097 missing (27.43%)\n",
      "HITTEST_A: 2616 missing (8.86%)\n",
      "HITCOMM_A: 2616 missing (8.86%)\n",
      "HITLOOK_A: 2616 missing (8.86%)\n",
      "ACCSSHOM_A: 2616 missing (8.86%)\n",
      "USPLKIND_A: 2921 missing (9.89%)\n",
      "WELLVIS_A: 24245 missing (82.13%)\n",
      "WELLNESS_A: 293 missing (0.99%)\n",
      "LCVDACT_A: 28459 missing (96.40%)\n",
      "SYMPNOW1_A: 27124 missing (91.88%)\n",
      "LONGCOVD1_A: 14168 missing (47.99%)\n",
      "PAYNOBLLNW_A: 26559 missing (89.96%)\n",
      "HINOTMYR_A: 28561 missing (96.74%)\n",
      "HINOTYR_A: 1973 missing (6.68%)\n",
      "RSNHIOTH_A: 27533 missing (93.26%)\n",
      "RSNHIWAIT_A: 27533 missing (93.26%)\n",
      "RSNHIMEET_A: 27533 missing (93.26%)\n",
      "RSNHICONF_A: 27533 missing (93.26%)\n",
      "RSNHIELIG_A: 27533 missing (93.26%)\n",
      "RSNHIWANT_A: 27533 missing (93.26%)\n",
      "RSNHICOST_A: 27533 missing (93.26%)\n",
      "HISTOPELIG_A: 28620 missing (96.94%)\n",
      "HISTOPCOST_A: 28620 missing (96.94%)\n",
      "HISTOPAGE_A: 28620 missing (96.94%)\n",
      "HISTOPMISS_A: 28620 missing (96.94%)\n",
      "HISTOPJOB_A: 28620 missing (96.94%)\n",
      "HILASTMY_A: 28993 missing (98.21%)\n",
      "HILAST_A: 27533 missing (93.26%)\n",
      "MILSPC3_A: 27711 missing (93.87%)\n",
      "MILSPC2_A: 27711 missing (93.87%)\n",
      "MILSPC1_A: 28115 missing (95.23%)\n",
      "OGHDHP_A: 29500 missing (99.93%)\n",
      "OGDEDUC_A: 29453 missing (99.77%)\n",
      "OGPREM_A: 29453 missing (99.77%)\n",
      "OGXCHNG_A: 29453 missing (99.77%)\n",
      "OPHDHP_A: 29472 missing (99.83%)\n",
      "OPDEDUC_A: 29355 missing (99.43%)\n",
      "OPPREM_A: 29355 missing (99.43%)\n",
      "OPXCHNG_A: 29355 missing (99.43%)\n",
      "CHHDHP_A: 29521 missing (100.00%)\n",
      "CHDEDUC_A: 29519 missing (99.99%)\n",
      "CHPREM_A: 29519 missing (99.99%)\n",
      "CHXCHNG_A: 29519 missing (99.99%)\n",
      "PRVSCOV2_A: 28998 missing (98.23%)\n",
      "PRVSCOV1_A: 11453 missing (38.79%)\n",
      "PRDNCOV2_A: 28998 missing (98.23%)\n",
      "PRDNCOV1_A: 11453 missing (38.79%)\n",
      "PRRXCOV2_A: 28998 missing (98.23%)\n",
      "PRRXCOV1_A: 11453 missing (38.79%)\n",
      "HSAHRA2_A: 29448 missing (99.75%)\n",
      "HSAHRA1_A: 22905 missing (77.59%)\n",
      "PRHDHP2_A: 29315 missing (99.30%)\n",
      "PRHDHP1_A: 16968 missing (57.48%)\n",
      "PRDEDUC2_A: 28998 missing (98.23%)\n",
      "PRDEDUC1_A: 11453 missing (38.79%)\n",
      "PLN2PAY6_A: 28998 missing (98.23%)\n",
      "PLN2PAY5_A: 28998 missing (98.23%)\n",
      "PLN2PAY4_A: 28998 missing (98.23%)\n",
      "PLN2PAY3_A: 28998 missing (98.23%)\n",
      "PLN2PAY2_A: 28998 missing (98.23%)\n",
      "PLN2PAY1_A: 28998 missing (98.23%)\n",
      "PLN1PAY6_A: 11453 missing (38.79%)\n",
      "PLN1PAY5_A: 11453 missing (38.79%)\n",
      "PLN1PAY4_A: 11453 missing (38.79%)\n",
      "PLN1PAY3_A: 11453 missing (38.79%)\n",
      "PLN1PAY2_A: 11453 missing (38.79%)\n",
      "PLN1PAY1_A: 11453 missing (38.79%)\n",
      "PLNEXCHG2_A: 29387 missing (99.54%)\n",
      "PLNEXCHG1_A: 26079 missing (88.34%)\n",
      "PRPOLH2_A: 29365 missing (99.47%)\n",
      "PRPOLH1_A: 25769 missing (87.29%)\n",
      "PRPLCOV2_A: 29155 missing (98.76%)\n",
      "PRPLCOV1_A: 15861 missing (53.73%)\n",
      "POLHLD2_A: 28998 missing (98.23%)\n",
      "POLHLD1_A: 11453 missing (38.79%)\n",
      "MAHDHP_A: 29388 missing (99.55%)\n",
      "MADEDUC_A: 25664 missing (86.93%)\n",
      "MAPREM_A: 25664 missing (86.93%)\n",
      "MAXCHNG_A: 25664 missing (86.93%)\n",
      "MCPARTD_A: 19472 missing (65.96%)\n",
      "MCVSCOV_A: 24949 missing (84.51%)\n",
      "MCDNCOV_A: 24949 missing (84.51%)\n",
      "MCHMO_A: 19929 missing (67.51%)\n",
      "MCCHOICE_A: 19929 missing (67.51%)\n",
      "MCPART_A: 19472 missing (65.96%)\n",
      "MCAIDPRB_A: 27538 missing (93.28%)\n",
      "MCAREPRB_A: 28285 missing (95.81%)\n",
      "DEVDONSET_A: 24983 missing (84.63%)\n",
      "COGAMTDFF_A: 24031 missing (81.40%)\n",
      "COGFRQDFF_A: 24031 missing (81.40%)\n",
      "COGTYPEDFF_A: 23153 missing (78.43%)\n",
      "EQSTEPS_A: 27482 missing (93.09%)\n",
      "EQWLK13M_A: 27816 missing (94.22%)\n",
      "EQWLK100_A: 27482 missing (93.09%)\n",
      "NOEQSTEPS_A: 26763 missing (90.65%)\n",
      "NOEQWLK13M_A: 27763 missing (94.04%)\n",
      "NOEQWLK100_A: 26763 missing (90.65%)\n",
      "PERASST_A: 26763 missing (90.65%)\n",
      "WCHAIR_A: 26763 missing (90.65%)\n",
      "CANEWLKR_A: 26763 missing (90.65%)\n",
      "STEPS_A: 2759 missing (9.35%)\n",
      "WLK13M_A: 2946 missing (9.98%)\n",
      "WLK100_A: 2759 missing (9.35%)\n",
      "HEARAIDFR_A: 27788 missing (94.13%)\n",
      "PREGNOW_A: 22805 missing (77.25%)\n",
      "VIMLSCA_A: 27368 missing (92.70%)\n",
      "VIMCAEV_A: 15045 missing (50.96%)\n",
      "VIMCSURG_A: 10715 missing (36.29%)\n",
      "VIMLSMD_A: 28744 missing (97.36%)\n",
      "VIMMDEV_A: 10715 missing (36.29%)\n",
      "VIMLSGL_A: 28434 missing (96.31%)\n",
      "VIMLSDR_A: 29152 missing (98.75%)\n",
      "EPIDR_A: 28954 missing (98.08%)\n",
      "EPIMED_A: 28954 missing (98.08%)\n",
      "CFSNOW_A: 29041 missing (98.37%)\n",
      "DIBTYPE_A: 26228 missing (88.84%)\n",
      "DIBINSSTYR_A: 29492 missing (99.90%)\n",
      "DIBINSSTOP_A: 28474 missing (96.45%)\n",
      "DIBINSTIME_A: 28474 missing (96.45%)\n",
      "DIBINS_A: 23194 missing (78.57%)\n",
      "DIBPILL_A: 23194 missing (78.57%)\n",
      "GESDIB_A: 13463 missing (45.60%)\n",
      "ASER12M_A: 25169 missing (85.26%)\n",
      "ASAT12M_A: 25169 missing (85.26%)\n",
      "ASTILL_A: 25169 missing (85.26%)\n",
      "ASPONOWN_A: 14343 missing (48.58%)\n",
      "ASPMEDSTP_A: 27999 missing (94.84%)\n",
      "ASPMEDNOWN_A: 23694 missing (80.26%)\n",
      "ASPMEDEV_A: 8514 missing (28.84%)\n",
      "CHLMED_A: 19918 missing (67.47%)\n",
      "CHL12M_A: 19918 missing (67.47%)\n",
      "HYPMED_A: 18428 missing (62.42%)\n",
      "HYP12M_A: 20023 missing (67.82%)\n",
      "HYPDIF_A: 18428 missing (62.42%)\n",
      "PROXYREL_A: 28985 missing (98.18%)\n",
      "PROXY_A: 28969 missing (98.13%)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values for all columns and display the count and percentage\n",
    "missing_values = df_copy.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df_copy)) * 100\n",
    "\n",
    "# Count columns with missing values\n",
    "missing_columns_count = (df_copy.isnull().sum() > 0).sum()\n",
    "print(f\"Number of columns with missing values: {missing_columns_count}\")\n",
    "\n",
    "\n",
    "# Filter only columns with missing values\n",
    "missing_data = missing_values[missing_values > 0]\n",
    "\n",
    "# Print missing values and percentages\n",
    "print(\"Columns with Missing Values:\")\n",
    "for col in missing_data.index:\n",
    "    print(f\"{col}: {missing_data[col]} missing ({missing_percentage[col]:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns after dropping: 294\n"
     ]
    }
   ],
   "source": [
    "# Recalculate missing percentages based on df_copy\n",
    "missing_percent = (df_copy.isnull().sum() / len(df_copy)) * 100  \n",
    "\n",
    "# Select only columns where missing percentage is less than 50%\n",
    "df_copy = df_copy.loc[:, missing_percent < 50]\n",
    "\n",
    "print(f\"Remaining columns after dropping: {df_copy.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values after dropping columns: 733072\n"
     ]
    }
   ],
   "source": [
    "# Check how many missing values remain\n",
    "total_missing = df_copy.isnull().sum().sum()\n",
    "print(f\"Total missing values after dropping columns: {total_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 29522\n",
      "Rows with at least 80% valid data: 29225\n",
      "Percentage of rows with â‰¥80% valid data: 98.99%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the threshold (50% of total columns)\n",
    "valid_data_threshold = int(df_copy.shape[1] * 0.8)\n",
    "\n",
    "# Count rows that have at least 50% valid (non-missing) data\n",
    "rows_with_80_valid = (df_copy.notnull().sum(axis=1) >= valid_data_threshold).sum()\n",
    "\n",
    "# Print results\n",
    "print(f\"Total rows: {df_copy.shape[0]}\")\n",
    "print(f\"Rows with at least 80% valid data: {rows_with_80_valid}\")\n",
    "print(f\"Percentage of rows with â‰¥80% valid data: {(rows_with_80_valid / df_copy.shape[0]) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New total rows after dropping low-validity rows: 29225\n"
     ]
    }
   ],
   "source": [
    "df_copy = df_copy.dropna(thresh=int(df_copy.shape[1] * 0.8))\n",
    "print(f\"New total rows after dropping low-validity rows: {df_copy.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values after row filtering: 713714\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total missing values after row filtering: {df_copy.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop single categorical column for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Set (X): (29225, 292)\n",
      "Target (y): (29225,)\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable (Life Satisfaction)\n",
    "y = df_copy[\"LSATIS4_A\"]  # Target variable\n",
    "X = df_copy.drop(columns=[\"LSATIS4_A\"])  # Features (everything except target)\n",
    "\n",
    "# Confirm separation\n",
    "print(f\"Feature Set (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20457, 292), X_val shape: (8768, 292)\n",
      "y_train shape: (20457,), y_val shape: (8768,)\n"
     ]
    }
   ],
   "source": [
    "#Train/Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.3, \n",
    "                                                  random_state = 0, \n",
    "                                                  stratify = y, \n",
    "                                                  shuffle = True)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, X_val shape: {X_val.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ New training set size: 20408\n",
      "ðŸ”¹ New validation set size: 8747\n"
     ]
    }
   ],
   "source": [
    "# Keep only valid target labels (1, 2, 3, 4)\n",
    "valid_classes = [1, 2, 3, 4]\n",
    "mask = y_train.isin(valid_classes)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "mask_val = y_val.isin(valid_classes)\n",
    "X_val = X_val[mask_val]\n",
    "y_val = y_val[mask_val]\n",
    "\n",
    "print(f\"ðŸ”¹ New training set size: {X_train.shape[0]}\")\n",
    "print(f\"ðŸ”¹ New validation set size: {X_val.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X_train after imputation: 0\n",
      "Missing values in X_val after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Replace NaNs with median values\n",
    "\n",
    "# Fill missing values in X_train using median\n",
    "X_train.fillna(X_train.median(), inplace=True)\n",
    "\n",
    "# Apply same imputation to X_val using X_train's median values\n",
    "X_val.fillna(X_train.median(), inplace=True)\n",
    "\n",
    "# Confirm no missing values remain\n",
    "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_val after imputation: {X_val.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spearman Correlation\n",
    "-Randomly select which feature to drop from two highly-correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 32 highly correlated features.\n",
      "New X_train shape: (20408, 260), New X_val shape: (8747, 260)\n"
     ]
    }
   ],
   "source": [
    "# Compute correlation matrix\n",
    "corr_matrix = X_train.corr(method='spearman').abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find columns with correlation > 0.9\n",
    "high_corr_features = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "\n",
    "# Drop highly correlated features from both train and validation sets\n",
    "X_train = X_train.drop(columns=high_corr_features)\n",
    "X_val = X_val.drop(columns=high_corr_features)\n",
    "\n",
    "print(f\"Dropped {len(high_corr_features)} highly correlated features.\")\n",
    "print(f\"New X_train shape: {X_train.shape}, New X_val shape: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE that selects the top 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Top 30 Most Important Features (RFE):\n",
      "           Feature  RFE_Rank\n",
      "0           URBRRL         1\n",
      "27      HEIGHTTC_A         1\n",
      "47         EDUCP_A         1\n",
      "51          REGION         1\n",
      "52        INTV_QRT         1\n",
      "55          AGEP_A         1\n",
      "62     HOUYRSLIV_A         1\n",
      "91    HRTESTLAST_A         1\n",
      "96      AHEARST1_A         1\n",
      "99      AVISEXAM_A         1\n",
      "116     PAIFRQ3M_A         1\n",
      "125     DISCRIM1_A         1\n",
      "128        PHQ42_A         1\n",
      "134      DEPFREQ_A         1\n",
      "137      ANXFREQ_A         1\n",
      "150    CVDVAC1M1_A         1\n",
      "151  SHTCVD19NM1_A         1\n",
      "154      SHTFLUM_A         1\n",
      "188      DENPREV_A         1\n",
      "254       PHSTAT_A         1\n",
      "26    WEIGHTLBTC_A         1\n",
      "22    EMDINDSTN2_A         1\n",
      "129        PHQ41_A         1\n",
      "259         WTFA_A         1\n",
      "6           PSTRAT         1\n",
      "21    EMDOCCUPN2_A         1\n",
      "5             PPSU         1\n",
      "13       MARSTAT_A         1\n",
      "20     EMPWKHRS3_A         1\n",
      "1         RATCAT_A         1\n",
      "\n",
      "âœ… Selected 30 features using RFE.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''# Train RFE with Random Forest\n",
    "rfe_selector = RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=0), n_features_to_select=30)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "\n",
    "# Store RFE feature rankings\n",
    "rfe_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"RFE_Rank\": rfe_selector.ranking_  # Lower rank = more important\n",
    "})\n",
    "\n",
    "# Sort by rank (lower is better)\n",
    "rfe_ranking = rfe_ranking.sort_values(by=\"RFE_Rank\", ascending=True)\n",
    "\n",
    "# Store the top 30 RFE features\n",
    "selected_features_rfe = rfe_ranking[\"Feature\"].head(30).tolist()\n",
    "\n",
    "# Print the top 30 RFE features\n",
    "print(\"\\nðŸ”¹ Top 30 Most Important Features (RFE):\")\n",
    "print(rfe_ranking.head(30))\n",
    "\n",
    "print(f\"\\nâœ… Selected {len(selected_features_rfe)} features using RFE.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE with rankings for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train RFE but keep rankings for ALL features\u001b[39;00m\n\u001b[0;32m      2\u001b[0m rfe_selector \u001b[38;5;241m=\u001b[39m RFE(estimator\u001b[38;5;241m=\u001b[39mRandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), n_features_to_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrfe_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Get rankings for all features\u001b[39;00m\n\u001b[0;32m      6\u001b[0m rfe_ranking \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: X_train\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRFE_Rank\u001b[39m\u001b[38;5;124m\"\u001b[39m: rfe_selector\u001b[38;5;241m.\u001b[39mranking_  \u001b[38;5;66;03m# Lower rank = more important\u001b[39;00m\n\u001b[0;32m      9\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:264\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:311\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 311\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    314\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    315\u001b[0m     estimator,\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    317\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    318\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train RFE but keep rankings for ALL features\n",
    "rfe_selector = RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=0), n_features_to_select=1, step=1)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "\n",
    "# Get rankings for all features\n",
    "rfe_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"RFE_Rank\": rfe_selector.ranking_  # Lower rank = more important\n",
    "})\n",
    "\n",
    "# Sort features by ranking\n",
    "rfe_ranking = rfe_ranking.sort_values(by=\"RFE_Rank\", ascending=True)\n",
    "\n",
    "# Print rankings (top 30)\n",
    "print(\"\\nðŸ”¹ Full RFE Feature Rankings:\")\n",
    "print(rfe_ranking.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFECV to determine optimal number of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=0, class_weight=\"balanced\")\n",
    "\n",
    "# ðŸ”¹ Use RFECV to determine the optimal number of features\n",
    "rfecv = RFECV(estimator=rf_classifier, step=1, cv=StratifiedKFold(5), scoring='accuracy', n_jobs=-1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# ðŸ”¹ Get the optimal number of features\n",
    "optimal_features = X_train.columns[rfecv.support_]  # Boolean mask of selected features\n",
    "num_selected_features = sum(rfecv.support_)  # Count selected features\n",
    "\n",
    "# ðŸ”¹ Print results\n",
    "print(f\"âœ… Optimal number of features selected by RFECV: {num_selected_features}\")\n",
    "print(f\"ðŸ”¹ Selected Features: {list(optimal_features)}\")\n",
    "\n",
    "# ðŸ”¹ Filter dataset to keep only selected features\n",
    "X_train_selected = X_train[optimal_features]\n",
    "X_val_selected = X_val[optimal_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RATCAT_A', 'PPSU', 'PSTRAT', 'MARSTAT_A', 'EMDOCCUPN2_A',\n",
      "       'EMDINDSTN2_A', 'WEIGHTLBTC_A', 'HEIGHTTC_A', 'EDUCP_A', 'AGEP_A',\n",
      "       'AVISEXAM_A', 'DISCRIM2_A', 'PHQ42_A', 'DEPFREQ_A', 'ANXFREQ_A',\n",
      "       'CVDVAC1M1_A', 'SHTCVD19NM1_A', 'SHTFLUM_A', 'PHSTAT_A', 'WTFA_A'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stores top 30 most important lasso features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Top 30 Most Important Features (LASSO):\n",
      "          Feature  Lasso_Coeff  Abs_Lasso_Coeff\n",
      "254      PHSTAT_A     0.151777         0.151777\n",
      "134     DEPFREQ_A    -0.088054         0.088054\n",
      "128       PHQ42_A     0.054759         0.054759\n",
      "137     ANXFREQ_A    -0.046543         0.046543\n",
      "13      MARSTAT_A     0.046137         0.046137\n",
      "129       PHQ41_A     0.039336         0.039336\n",
      "73     CEVOLUN1_A     0.032701         0.032701\n",
      "32   PHQ2SCREEN_A    -0.032232         0.032232\n",
      "1        RATCAT_A    -0.025629         0.025629\n",
      "191    PAYWORRY_A    -0.024567         0.024567\n",
      "30     PCNT18UPTC    -0.022252         0.022252\n",
      "63   FDSBALANCE_A    -0.019823         0.019823\n",
      "96     AHEARST1_A     0.018884         0.018884\n",
      "54          SEX_A    -0.018648         0.018648\n",
      "125    DISCRIM1_A    -0.017858         0.017858\n",
      "19   EMPWRKLSW1_A    -0.017215         0.017215\n",
      "209   SOCSCLPAR_A     0.016341         0.016341\n",
      "59     TRANSPOR_A    -0.016050         0.016050\n",
      "180    MEDDL12M_A    -0.015133         0.015133\n",
      "188     DENPREV_A     0.013678         0.013678\n",
      "57     CEVOTELC_A     0.013478         0.013478\n",
      "77    EMPSICKLV_A     0.012649         0.012649\n",
      "184    WELLNESS_A     0.011247         0.011247\n",
      "214   COGMEMDFF_A     0.011236         0.011236\n",
      "7      HISPALLP_A     0.011234         0.011234\n",
      "135    ANXLEVEL_A     0.010933         0.010933\n",
      "23    SMKECIGST_A    -0.010618         0.010618\n",
      "62    HOUYRSLIV_A     0.010579         0.010579\n",
      "174     HITCOMM_A     0.009271         0.009271\n",
      "29   EMERG12MTC_A    -0.009204         0.009204\n",
      "\n",
      "âœ… Selected 30 features using LASSO.\n"
     ]
    }
   ],
   "source": [
    "# Standardize Features (LASSO is sensitive to scale)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# ðŸ”¹ Train LASSO with Cross-Validation\n",
    "lasso = LassoCV(cv=5, random_state=0)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Store LASSO feature coefficients\n",
    "lasso_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Lasso_Coeff\": lasso.coef_\n",
    "})\n",
    "\n",
    "# Convert Lasso Coefficients to absolute values\n",
    "lasso_ranking[\"Abs_Lasso_Coeff\"] = np.abs(lasso_ranking[\"Lasso_Coeff\"])\n",
    "\n",
    "# Sort by absolute LASSO coefficient (higher is better)\n",
    "lasso_ranking = lasso_ranking.sort_values(by=\"Abs_Lasso_Coeff\", ascending=False)\n",
    "\n",
    "# Store the top 30 LASSO features\n",
    "selected_features_lasso = lasso_ranking[\"Feature\"].head(30).tolist()\n",
    "\n",
    "# ðŸ”¹ Print the top 30 LASSO features\n",
    "print(\"\\nðŸ”¹ Top 30 Most Important Features (LASSO):\")\n",
    "print(lasso_ranking.head(30))\n",
    "\n",
    "print(f\"\\nâœ… Selected {len(selected_features_lasso)} features using LASSO.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso that ranks all important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ðŸ”¹ Standardize Features (LASSO is sensitive to scale)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# ðŸ”¹ Train LASSO with Cross-Validation\n",
    "lasso = LassoCV(cv=5, random_state=0)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ðŸ”¹ Store LASSO feature coefficients\n",
    "lasso_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Lasso_Coeff\": lasso.coef_\n",
    "})\n",
    "\n",
    "# ðŸ”¹ Convert Lasso Coefficients to absolute values\n",
    "lasso_ranking[\"Abs_Lasso_Coeff\"] = np.abs(lasso_ranking[\"Lasso_Coeff\"])\n",
    "\n",
    "# ðŸ”¹ Sort ALL features by absolute LASSO coefficient (higher = better)\n",
    "lasso_ranking = lasso_ranking.sort_values(by=\"Abs_Lasso_Coeff\", ascending=False)\n",
    "\n",
    "# ðŸ”¹ Store ALL important features (i.e., non-zero coefficients)\n",
    "selected_features_lasso = lasso_ranking[lasso_ranking[\"Abs_Lasso_Coeff\"] > 0][\"Feature\"].tolist()\n",
    "\n",
    "# ðŸ”¹ Print the full feature importance ranking\n",
    "print(\"\\nðŸ”¹ Ranked Features by Importance (LASSO):\")\n",
    "print(lasso_ranking[[\"Feature\", \"Abs_Lasso_Coeff\"]])\n",
    "\n",
    "print(f\"\\nâœ… Selected {len(selected_features_lasso)} important features using LASSO.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unweighted combination of lasso and RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Final Top 30 Features (Based on RFE & LASSO):\n",
      "           Feature  RFE_Score  Lasso_Score  Final_Score\n",
      "1         RATCAT_A          1            1            2\n",
      "62     HOUYRSLIV_A          1            1            2\n",
      "128        PHQ42_A          1            1            2\n",
      "129        PHQ41_A          1            1            2\n",
      "96      AHEARST1_A          1            1            2\n",
      "134      DEPFREQ_A          1            1            2\n",
      "137      ANXFREQ_A          1            1            2\n",
      "13       MARSTAT_A          1            1            2\n",
      "125     DISCRIM1_A          1            1            2\n",
      "188      DENPREV_A          1            1            2\n",
      "254       PHSTAT_A          1            1            2\n",
      "59      TRANSPOR_A          0            1            1\n",
      "99      AVISEXAM_A          1            0            1\n",
      "73      CEVOLUN1_A          0            1            1\n",
      "77     EMPSICKLV_A          0            1            1\n",
      "57      CEVOTELC_A          0            1            1\n",
      "91    HRTESTLAST_A          1            0            1\n",
      "55          AGEP_A          1            0            1\n",
      "54           SEX_A          0            1            1\n",
      "52        INTV_QRT          1            0            1\n",
      "63    FDSBALANCE_A          0            1            1\n",
      "0           URBRRL          1            0            1\n",
      "116     PAIFRQ3M_A          1            0            1\n",
      "47         EDUCP_A          1            0            1\n",
      "135     ANXLEVEL_A          0            1            1\n",
      "150    CVDVAC1M1_A          1            0            1\n",
      "151  SHTCVD19NM1_A          1            0            1\n",
      "154      SHTFLUM_A          1            0            1\n",
      "174      HITCOMM_A          0            1            1\n",
      "180     MEDDL12M_A          0            1            1\n",
      "\n",
      "âœ… Final selection: 30 most important features.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Combine RFE and LASSO features into a DataFrame\n",
    "feature_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns\n",
    "})\n",
    "\n",
    "# ðŸ”¹ Assign scores based on selection:\n",
    "feature_ranking[\"RFE_Score\"] = feature_ranking[\"Feature\"].apply(lambda x: 1 if x in selected_features_rfe else 0)\n",
    "feature_ranking[\"Lasso_Score\"] = feature_ranking[\"Feature\"].apply(lambda x: 1 if x in selected_features_lasso else 0)\n",
    "\n",
    "# ðŸ”¹ Compute final importance score (sum of both methods)\n",
    "feature_ranking[\"Final_Score\"] = feature_ranking[\"RFE_Score\"] + feature_ranking[\"Lasso_Score\"]\n",
    "\n",
    "# Sort by final score (higher score = more important)\n",
    "feature_ranking = feature_ranking.sort_values(by=\"Final_Score\", ascending=False)\n",
    "\n",
    "# Select the top 30 final features\n",
    "selected_features_final = feature_ranking[\"Feature\"].head(30).tolist()\n",
    "\n",
    "# ðŸ”¹ Print the top 30 final selected features\n",
    "print(\"\\nðŸ”¹ Final Top 30 Features (Based on RFE & LASSO):\")\n",
    "print(feature_ranking.head(30))\n",
    "\n",
    "print(f\"\\nâœ… Final selection: {len(selected_features_final)} most important features.\")\n",
    "\n",
    "# ðŸ”¹ Filter dataset to keep only selected features\n",
    "X_train_selected = X_train[selected_features_final]\n",
    "X_val_selected = X_val[selected_features_final]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted combination of lasso and RFE\n",
    "-Requires RFE to rank ALL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame to store feature rankings\n",
    "feature_ranking = pd.DataFrame({\"Feature\": X_train.columns})\n",
    "\n",
    "# ðŸ”¹ Assign scores based on rankings & importance:\n",
    "feature_ranking[\"RFE_Rank\"] = feature_ranking[\"Feature\"].map(lambda x: rfe_ranking_dict.get(x, np.nan))  # Lower is better\n",
    "feature_ranking[\"Lasso_Coeff\"] = feature_ranking[\"Feature\"].map(lambda x: lasso_coeff_dict.get(x, 0))  # Higher is better\n",
    "\n",
    "# ðŸ”¹ Normalize scores for fair comparison\n",
    "feature_ranking[\"Norm_RFE\"] = (feature_ranking[\"RFE_Rank\"].max() - feature_ranking[\"RFE_Rank\"]) / (feature_ranking[\"RFE_Rank\"].max() - feature_ranking[\"RFE_Rank\"].min())  # Invert so higher = better\n",
    "feature_ranking[\"Norm_Lasso\"] = np.abs(feature_ranking[\"Lasso_Coeff\"]) / np.abs(feature_ranking[\"Lasso_Coeff\"]).max()  # Higher = better\n",
    "\n",
    "# ðŸ”¹ Compute final weighted importance score\n",
    "feature_ranking[\"Final_Score\"] = (\n",
    "    feature_ranking[\"Norm_RFE\"] * 0.5 +  # RFE importance (50%)\n",
    "    feature_ranking[\"Norm_Lasso\"] * 0.5  # LASSO importance (50%)\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Sort by final importance score\n",
    "feature_ranking = feature_ranking.sort_values(by=\"Final_Score\", ascending=False)\n",
    "\n",
    "# ðŸ”¹ Select top 30 most important features\n",
    "selected_features_final = feature_ranking[\"Feature\"].head(30).tolist()\n",
    "\n",
    "# ðŸ”¹ Print the final ranked top 30 features\n",
    "print(\"\\nðŸ”¹ Final Top 30 Features (Weighted Ranking):\")\n",
    "print(feature_ranking[[\"Feature\", \"Final_Score\"]].head(30))\n",
    "\n",
    "print(f\"\\nâœ… Final selection: {len(selected_features_final)} most important features.\")\n",
    "\n",
    "# ðŸ”¹ Filter dataset to keep only selected features\n",
    "X_train_selected = X_train[selected_features_final]\n",
    "X_val_selected = X_val[selected_features_final]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apparently this is the final optimized RFE combined with lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m rf_classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m rfecv \u001b[38;5;241m=\u001b[39m RFECV(estimator\u001b[38;5;241m=\u001b[39mrf_classifier, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39mStratifiedKFold(\u001b[38;5;241m5\u001b[39m), scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mrfecv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get RFECV-selected features\u001b[39;00m\n\u001b[0;32m      8\u001b[0m rfecv_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mcolumns[rfecv\u001b[38;5;241m.\u001b[39msupport_])\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:752\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    749\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    750\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m--> 752\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[0;32m    758\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  Run RFECV to Select Optimal Features\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=0, class_weight=\"balanced\")\n",
    "\n",
    "rfecv = RFECV(estimator=rf_classifier, step=1, cv=StratifiedKFold(5), scoring='accuracy', n_jobs=-1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# Get RFECV-selected features\n",
    "rfecv_features = set(X_train.columns[rfecv.support_])\n",
    "num_rfecv_features = len(rfecv_features)\n",
    "print(f\"âœ… RFECV selected {num_rfecv_features} features.\")\n",
    "\n",
    "# 2ï¸âƒ£ Run LASSO to Identify Important Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "lasso = LassoCV(cv=5, random_state=0)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get LASSO-selected features (non-zero coefficients)\n",
    "lasso_features = set(X_train.columns[lasso.coef_ != 0])\n",
    "num_lasso_features = len(lasso_features)\n",
    "print(f\"âœ… LASSO selected {num_lasso_features} features.\")\n",
    "\n",
    "# Combine RFECV + LASSO Features\n",
    "final_features = rfecv_features.union(lasso_features)  # Merge both sets\n",
    "num_final_features = len(final_features)\n",
    "\n",
    "# Print the final feature selection results\n",
    "print(f\"\\nðŸ”¹ Final feature set includes {num_final_features} features (RFECV + LASSO).\")\n",
    "print(f\"ðŸ“ Features Selected: {list(final_features)}\")\n",
    "\n",
    "# Filter Dataset to Keep Only Selected Features\n",
    "X_train_selected = X_train[list(final_features)]\n",
    "X_val_selected = X_val[list(final_features)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions for both training and validation sets\n",
    "lr_train_preds = model.predict(X_train)\n",
    "lr_val_preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Training Set Metrics:\n",
      "  - Accuracy: 0.5154\n",
      "  - Precision: 0.4513\n",
      "  - Recall: 0.5154\n",
      "  - F1-score: 0.3625\n",
      "\n",
      "ðŸ”¹ Validation Set Metrics:\n",
      "  - Accuracy: 0.5140\n",
      "  - Precision: 0.4348\n",
      "  - Recall: 0.5140\n",
      "  - F1-score: 0.3612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate classification performance\n",
    "def evaluate_classification(y_true, y_pred, dataset=\"Validation\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"ðŸ”¹ {dataset} Set Metrics:\")\n",
    "    print(f\"  - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  - Precision: {precision:.4f}\")\n",
    "    print(f\"  - Recall: {recall:.4f}\")\n",
    "    print(f\"  - F1-score: {f1:.4f}\\n\")\n",
    "\n",
    "# Evaluate on Training Set\n",
    "evaluate_classification(y_train, lr_train_preds, dataset=\"Training\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "evaluate_classification(y_val, lr_val_preds, dataset=\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Important Features:\n",
      "          Feature  Coefficient  Abs_Coefficient\n",
      "33         CHIP_A    -0.310883         0.310883\n",
      "150    HIKIND07_A     0.275841         0.275841\n",
      "31          IHS_A    -0.241593         0.241593\n",
      "197      PHSTAT_A     0.146455         0.146455\n",
      "152    HIKIND05_A     0.106269         0.106269\n",
      "191       STREV_A    -0.088309         0.088309\n",
      "24     PCNT18UPTC    -0.083287         0.083287\n",
      "184     DEMENEV_A     0.079963         0.079963\n",
      "107       PHQ42_A     0.076982         0.076982\n",
      "113     DEPFREQ_A    -0.071777         0.071777\n",
      "192        MIEV_A     0.067566         0.067566\n",
      "134    MEDDL12M_A    -0.064623         0.064623\n",
      "178      PSOREV_A    -0.059176         0.059176\n",
      "148    HIKIND09_A     0.059033         0.059033\n",
      "177       CFSEV_A     0.057343         0.057343\n",
      "55     TRANSPOR_A    -0.056124         0.056124\n",
      "42     PCNTADLT_A     0.055730         0.055730\n",
      "40    MLTFAMFLG_A    -0.053319         0.053319\n",
      "68    NATUSBORN_A     0.049873         0.049873\n",
      "16   EMPWRKLSW1_A    -0.049834         0.049834\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance from model coefficients (for Linear Regression)\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Coefficient\": model.coef_\n",
    "})\n",
    "\n",
    "# Sort by absolute coefficient value (most important first)\n",
    "feature_importance[\"Abs_Coefficient\"] = feature_importance[\"Coefficient\"].abs()\n",
    "feature_importance = feature_importance.sort_values(by=\"Abs_Coefficient\", ascending=False)\n",
    "\n",
    "# Display the top 20 most important features\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=200,  # More trees\n",
    "    max_depth=10,  # Prevent overfitting\n",
    "    min_samples_split=5,  # Require more samples to split\n",
    "    min_samples_leaf=2,  # Require more samples per leaf\n",
    "    class_weight='balanced',  # Adjust for imbalanced data\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Train classifier\n",
    "rf_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_train_preds = rf_classifier.predict(X_train_selected)\n",
    "rf_val_preds = rf_classifier.predict(X_val_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Training Set Metrics:\n",
      "  - Accuracy: 0.7098\n",
      "  - Precision: 0.7203\n",
      "  - Recall: 0.7098\n",
      "  - F1-score: 0.7102\n",
      "\n",
      "ðŸ”¹ Validation Set Metrics:\n",
      "  - Accuracy: 0.6377\n",
      "  - Precision: 0.6478\n",
      "  - Recall: 0.6377\n",
      "  - F1-score: 0.6399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to evaluate classification performance\n",
    "def evaluate_classification(y_true, y_pred, dataset=\"Validation\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"ðŸ”¹ {dataset} Set Metrics:\")\n",
    "    print(f\"  - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  - Precision: {precision:.4f}\")\n",
    "    print(f\"  - Recall: {recall:.4f}\")\n",
    "    print(f\"  - F1-score: {f1:.4f}\\n\")\n",
    "\n",
    "# Evaluate on Training Set\n",
    "evaluate_classification(y_train, rf_train_preds, dataset=\"Training\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "evaluate_classification(y_val, rf_val_preds, dataset=\"Validation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current High-Score: F1 = .6399 using Unweighted selection of top 30 RFE + Lasso\n",
    "\n",
    "Tried:\n",
    "All features\n",
    "Top 30 RFE + Lasso Unweighted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
