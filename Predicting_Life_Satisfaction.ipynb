{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Life Satisfaction with NHS Data: Which Lifestyle factors are most important for LS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website: https://www.cdc.gov/nchs/nhis/documentation/2023-nhis.html\n",
    "\n",
    "Dataset: C:\\Users\\sacar\\OneDrive\\Documents\\Projects\\Predicting MH with NHS Data\\adult23.csv\n",
    "\n",
    "Description: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "df = pd.read_csv(r'C:\\Users\\sacar\\OneDrive\\Documents\\Projects\\Predicting MH with NHS Data\\adult23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29522 entries, 0 to 29521\n",
      "Columns: 647 entries, URBRRL to POVRATTC_A\n",
      "dtypes: float64(442), int64(204), object(1)\n",
      "memory usage: 145.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URBRRL</th>\n",
       "      <th>RATCAT_A</th>\n",
       "      <th>INCTCFLG_A</th>\n",
       "      <th>IMPINCFLG_A</th>\n",
       "      <th>LANGSPECR_A</th>\n",
       "      <th>LANGSOC_A</th>\n",
       "      <th>LANGDOC_A</th>\n",
       "      <th>LANGMED_A</th>\n",
       "      <th>LANGHM_A</th>\n",
       "      <th>PPSU</th>\n",
       "      <th>...</th>\n",
       "      <th>PROXYREL_A</th>\n",
       "      <th>PROXY_A</th>\n",
       "      <th>AVAIL_A</th>\n",
       "      <th>HHSTAT_A</th>\n",
       "      <th>INTV_MON</th>\n",
       "      <th>RECTYPE</th>\n",
       "      <th>IMPNUM_A</th>\n",
       "      <th>WTFA_A</th>\n",
       "      <th>HHX</th>\n",
       "      <th>POVRATTC_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7371.139</td>\n",
       "      <td>H029691</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3146.794</td>\n",
       "      <td>H028812</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 647 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   URBRRL  RATCAT_A  INCTCFLG_A  IMPINCFLG_A  LANGSPECR_A  LANGSOC_A  \\\n",
       "0       3         4           0            0          NaN        NaN   \n",
       "1       4         8           0            0          NaN        NaN   \n",
       "\n",
       "   LANGDOC_A  LANGMED_A  LANGHM_A  PPSU  ...  PROXYREL_A  PROXY_A  AVAIL_A  \\\n",
       "0        NaN        NaN       NaN     2  ...         NaN      NaN        1   \n",
       "1        NaN        NaN       NaN     2  ...         NaN      NaN        1   \n",
       "\n",
       "   HHSTAT_A  INTV_MON  RECTYPE  IMPNUM_A    WTFA_A      HHX  POVRATTC_A  \n",
       "0         1         1       10         1  7371.139  H029691        1.01  \n",
       "1         1         1       10         1  3146.794  H028812        2.49  \n",
       "\n",
       "[2 rows x 647 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URBRRL</th>\n",
       "      <th>RATCAT_A</th>\n",
       "      <th>INCTCFLG_A</th>\n",
       "      <th>IMPINCFLG_A</th>\n",
       "      <th>LANGSPECR_A</th>\n",
       "      <th>LANGSOC_A</th>\n",
       "      <th>LANGDOC_A</th>\n",
       "      <th>LANGMED_A</th>\n",
       "      <th>LANGHM_A</th>\n",
       "      <th>PPSU</th>\n",
       "      <th>...</th>\n",
       "      <th>PHSTAT_A</th>\n",
       "      <th>PROXYREL_A</th>\n",
       "      <th>PROXY_A</th>\n",
       "      <th>AVAIL_A</th>\n",
       "      <th>HHSTAT_A</th>\n",
       "      <th>INTV_MON</th>\n",
       "      <th>RECTYPE</th>\n",
       "      <th>IMPNUM_A</th>\n",
       "      <th>WTFA_A</th>\n",
       "      <th>POVRATTC_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>4049.000000</td>\n",
       "      <td>3973.000000</td>\n",
       "      <td>4049.000000</td>\n",
       "      <td>4049.000000</td>\n",
       "      <td>22104.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.0</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.0</td>\n",
       "      <td>29522.0</td>\n",
       "      <td>29522.000000</td>\n",
       "      <td>29522.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.317119</td>\n",
       "      <td>9.666757</td>\n",
       "      <td>0.041664</td>\n",
       "      <td>0.373721</td>\n",
       "      <td>1.453445</td>\n",
       "      <td>1.480997</td>\n",
       "      <td>1.301309</td>\n",
       "      <td>1.392937</td>\n",
       "      <td>2.063563</td>\n",
       "      <td>31.375246</td>\n",
       "      <td>...</td>\n",
       "      <td>2.460369</td>\n",
       "      <td>1.286778</td>\n",
       "      <td>1.039783</td>\n",
       "      <td>1.205542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.472089</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8747.291918</td>\n",
       "      <td>4.106340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.061522</td>\n",
       "      <td>4.048065</td>\n",
       "      <td>0.199823</td>\n",
       "      <td>0.712244</td>\n",
       "      <td>0.801351</td>\n",
       "      <td>0.790779</td>\n",
       "      <td>0.631127</td>\n",
       "      <td>0.734160</td>\n",
       "      <td>1.287790</td>\n",
       "      <td>29.253976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.074983</td>\n",
       "      <td>0.668921</td>\n",
       "      <td>0.338166</td>\n",
       "      <td>1.087867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.444791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5690.650182</td>\n",
       "      <td>2.961649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1792.441000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4643.531750</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7374.546000</td>\n",
       "      <td>3.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10994.809500</td>\n",
       "      <td>5.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39925.600000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 646 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URBRRL      RATCAT_A    INCTCFLG_A   IMPINCFLG_A  LANGSPECR_A  \\\n",
       "count  29522.000000  29522.000000  29522.000000  29522.000000  4049.000000   \n",
       "mean       2.317119      9.666757      0.041664      0.373721     1.453445   \n",
       "std        1.061522      4.048065      0.199823      0.712244     0.801351   \n",
       "min        1.000000      1.000000      0.000000      0.000000     1.000000   \n",
       "25%        1.000000      7.000000      0.000000      0.000000     1.000000   \n",
       "50%        2.000000     10.000000      0.000000      0.000000     1.000000   \n",
       "75%        3.000000     14.000000      0.000000      0.000000     2.000000   \n",
       "max        4.000000     14.000000      1.000000      2.000000     9.000000   \n",
       "\n",
       "         LANGSOC_A    LANGDOC_A    LANGMED_A      LANGHM_A          PPSU  ...  \\\n",
       "count  3973.000000  4049.000000  4049.000000  22104.000000  29522.000000  ...   \n",
       "mean      1.480997     1.301309     1.392937      2.063563     31.375246  ...   \n",
       "std       0.790779     0.631127     0.734160      1.287790     29.253976  ...   \n",
       "min       1.000000     1.000000     1.000000      1.000000      1.000000  ...   \n",
       "25%       1.000000     1.000000     1.000000      2.000000      8.000000  ...   \n",
       "50%       1.000000     1.000000     1.000000      2.000000     24.000000  ...   \n",
       "75%       2.000000     2.000000     2.000000      2.000000     48.000000  ...   \n",
       "max       9.000000     9.000000     9.000000      9.000000    153.000000  ...   \n",
       "\n",
       "           PHSTAT_A  PROXYREL_A     PROXY_A       AVAIL_A  HHSTAT_A  \\\n",
       "count  29522.000000  537.000000  553.000000  29522.000000   29522.0   \n",
       "mean       2.460369    1.286778    1.039783      1.205542       1.0   \n",
       "std        1.074983    0.668921    0.338166      1.087867       0.0   \n",
       "min        1.000000    1.000000    1.000000      1.000000       1.0   \n",
       "25%        2.000000    1.000000    1.000000      1.000000       1.0   \n",
       "50%        2.000000    1.000000    1.000000      1.000000       1.0   \n",
       "75%        3.000000    1.000000    1.000000      1.000000       1.0   \n",
       "max        9.000000    4.000000    8.000000      8.000000       1.0   \n",
       "\n",
       "           INTV_MON  RECTYPE  IMPNUM_A        WTFA_A    POVRATTC_A  \n",
       "count  29522.000000  29522.0   29522.0  29522.000000  29522.000000  \n",
       "mean       6.472089     10.0       1.0   8747.291918      4.106340  \n",
       "std        3.444791      0.0       0.0   5690.650182      2.961649  \n",
       "min        1.000000     10.0       1.0   1792.441000      0.000000  \n",
       "25%        3.000000     10.0       1.0   4643.531750      1.800000  \n",
       "50%        7.000000     10.0       1.0   7374.546000      3.310000  \n",
       "75%        9.000000     10.0       1.0  10994.809500      5.650000  \n",
       "max       12.000000     10.0       1.0  39925.600000     11.000000  \n",
       "\n",
       "[8 rows x 646 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 29522 entries, 0 to 29521\n",
      "Series name: LSATIS4_A\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "29522 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 230.8 KB\n",
      "None\n",
      "[2 1 3 9 4 7]\n"
     ]
    }
   ],
   "source": [
    "print(df_copy[\"LSATIS4_A\"].info())  # Check column type and non-null values\n",
    "\n",
    "print(df_copy[\"LSATIS4_A\"].unique())  # Show unique values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values - Dropping Columns and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    647.000000\n",
      "mean      52.059685\n",
      "std       42.190768\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%       62.421245\n",
      "75%       93.630174\n",
      "max      100.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate missing value percentages\n",
    "missing_percent = df_copy.isnull().sum() / len(df_copy) * 100\n",
    "\n",
    "# Print summary\n",
    "print(missing_percent.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with missing values: 440\n",
      "Columns with Missing Values:\n",
      "LANGSPECR_A: 25473 missing (86.28%)\n",
      "LANGSOC_A: 25549 missing (86.54%)\n",
      "LANGDOC_A: 25473 missing (86.28%)\n",
      "LANGMED_A: 25473 missing (86.28%)\n",
      "LANGHM_A: 7418 missing (25.13%)\n",
      "SCHDYMSSTC_A: 27881 missing (94.44%)\n",
      "AFNOW: 8099 missing (27.43%)\n",
      "REPWRKDYTC_A: 28193 missing (95.50%)\n",
      "YRSINUS_A: 24820 missing (84.07%)\n",
      "PRTNREDUCP_A: 27652 missing (93.67%)\n",
      "SPOUSEDUCP_A: 17305 missing (58.62%)\n",
      "SASPPRACE_A: 15434 missing (52.28%)\n",
      "SASPPHISP_A: 15434 missing (52.28%)\n",
      "PRTNRAGETC_A: 27651 missing (93.66%)\n",
      "SPOUSAGETC_A: 17305 missing (58.62%)\n",
      "PRTNRWKFT_A: 28118 missing (95.24%)\n",
      "PRTNRWRK_A: 27660 missing (93.69%)\n",
      "SPOUSWKFT_A: 21989 missing (74.48%)\n",
      "SPOUSWRK_A: 17356 missing (58.79%)\n",
      "SPOUSESEX_A: 17306 missing (58.62%)\n",
      "PRTNRSEX_A: 27651 missing (93.66%)\n",
      "INJWRKDYTC_A: 27562 missing (93.36%)\n",
      "NUMINJTC_A: 27562 missing (93.36%)\n",
      "SHINGYEARP_A: 22275 missing (75.45%)\n",
      "HHRESPSA_FLG: 8637 missing (29.26%)\n",
      "EPINUMSEZP_A: 28954 missing (98.08%)\n",
      "EMPDYSMSS3_A: 11722 missing (39.71%)\n",
      "EMPLSTWOR1_A: 17471 missing (59.18%)\n",
      "EMPWRKFT1_A: 13144 missing (44.52%)\n",
      "EMPWKHRS3_A: 13167 missing (44.60%)\n",
      "EMDOCCUPN2_A: 11722 missing (39.71%)\n",
      "EMDOCCUPN1_A: 11722 missing (39.71%)\n",
      "EMDINDSTN2_A: 11722 missing (39.71%)\n",
      "EMDINDSTN1_A: 11722 missing (39.71%)\n",
      "DIBAGETC_A: 26228 missing (88.84%)\n",
      "DIFYRSTC1_A: 26228 missing (88.84%)\n",
      "DIBA1CNMT_A: 26432 missing (89.53%)\n",
      "COVER65_A: 19819 missing (67.13%)\n",
      "COVER_A: 9703 missing (32.87%)\n",
      "EXCHANGE_A: 11454 missing (38.80%)\n",
      "MILSPC1R_A: 27711 missing (93.87%)\n",
      "OGFLG_A: 29522 missing (100.00%)\n",
      "OPFLG_A: 29522 missing (100.00%)\n",
      "CHFLG_A: 29522 missing (100.00%)\n",
      "MAFLG_A: 29470 missing (99.82%)\n",
      "PLNWRKR2_A: 28998 missing (98.23%)\n",
      "PLNWRKR1_A: 11453 missing (38.79%)\n",
      "RSNHIMISS_A: 27533 missing (93.26%)\n",
      "RSNHIJOB_A: 27533 missing (93.26%)\n",
      "MCADVR_A: 24949 missing (84.51%)\n",
      "PRFLG_A: 28875 missing (97.81%)\n",
      "PLEXCHPR1_A: 28875 missing (97.81%)\n",
      "PRPREM1_A: 28875 missing (97.81%)\n",
      "PXCHNG1_A: 28875 missing (97.81%)\n",
      "HICOSTR2_A: 29114 missing (98.62%)\n",
      "HICOSTR1_A: 14963 missing (50.68%)\n",
      "PRPLCOV1_C_A: 29497 missing (99.92%)\n",
      "PRPLCOV2_C_A: 29518 missing (99.99%)\n",
      "PLEXCHOG_A: 29453 missing (99.77%)\n",
      "PLEXCHOP_A: 29355 missing (99.43%)\n",
      "EXCHPR2_A: 28998 missing (98.23%)\n",
      "EXCHPR1_A: 12101 missing (40.99%)\n",
      "MAXEDUCP_A: 78 missing (0.26%)\n",
      "COLRCAGETC_A: 29307 missing (99.27%)\n",
      "HDNCKAGETC_A: 29458 missing (99.78%)\n",
      "OTHERAGETC_A: 29193 missing (98.89%)\n",
      "UTERUAGETC_A: 29415 missing (99.64%)\n",
      "THYROAGETC_A: 29413 missing (99.63%)\n",
      "THROAAGETC_A: 29480 missing (99.86%)\n",
      "STOMAAGETC_A: 29501 missing (99.93%)\n",
      "SKNDKAGETC_A: 29307 missing (99.27%)\n",
      "SKNNMAGETC_A: 28707 missing (97.24%)\n",
      "SKNMAGETC_A: 29180 missing (98.84%)\n",
      "RECTUAGETC_A: 29502 missing (99.93%)\n",
      "PROSTAGETC_A: 29039 missing (98.36%)\n",
      "PANCRAGETC_A: 29502 missing (99.93%)\n",
      "OVARYAGETC_A: 29448 missing (99.75%)\n",
      "MOUTHAGETC_A: 29509 missing (99.96%)\n",
      "MELANAGETC_A: 29329 missing (99.35%)\n",
      "LYMPHAGETC_A: 29415 missing (99.64%)\n",
      "LUNGAGETC_A: 29377 missing (99.51%)\n",
      "LIVERAGETC_A: 29503 missing (99.94%)\n",
      "LEUKEAGETC_A: 29461 missing (99.79%)\n",
      "LARYNAGETC_A: 29513 missing (99.97%)\n",
      "GALLBAGETC_A: 29519 missing (99.99%)\n",
      "ESOPHAGETC_A: 29505 missing (99.94%)\n",
      "COLONAGETC_A: 29327 missing (99.34%)\n",
      "CERVIAGETC_A: 29346 missing (99.40%)\n",
      "BREASAGETC_A: 28769 missing (97.45%)\n",
      "BRAINAGETC_A: 29490 missing (99.89%)\n",
      "BONEAGETC_A: 29501 missing (99.93%)\n",
      "BLOODAGETC_A: 29496 missing (99.91%)\n",
      "BLADDAGETC_A: 29421 missing (99.66%)\n",
      "OTHERCANP_A: 25760 missing (87.26%)\n",
      "COLRCCAN_A: 25760 missing (87.26%)\n",
      "HDNCKCAN_A: 25760 missing (87.26%)\n",
      "UTERUCAN_A: 27376 missing (92.73%)\n",
      "THYROCAN_A: 25760 missing (87.26%)\n",
      "THROACAN_A: 25760 missing (87.26%)\n",
      "STOMACAN_A: 25760 missing (87.26%)\n",
      "SKNDKCAN_A: 25760 missing (87.26%)\n",
      "SKNNMCAN_A: 25760 missing (87.26%)\n",
      "SKNMCAN_A: 25760 missing (87.26%)\n",
      "RECTUCAN_A: 25760 missing (87.26%)\n",
      "PROSTCAN_A: 27906 missing (94.53%)\n",
      "PANCRCAN_A: 25760 missing (87.26%)\n",
      "OVARYCAN_A: 27376 missing (92.73%)\n",
      "MOUTHCAN_A: 25760 missing (87.26%)\n",
      "MELANCAN_A: 25760 missing (87.26%)\n",
      "LYMPHCAN_A: 25760 missing (87.26%)\n",
      "LUNGCAN_A: 25760 missing (87.26%)\n",
      "LIVERCAN_A: 25760 missing (87.26%)\n",
      "LEUKECAN_A: 25760 missing (87.26%)\n",
      "LARYNCAN_A: 25760 missing (87.26%)\n",
      "GALLBCAN_A: 25760 missing (87.26%)\n",
      "ESOPHCAN_A: 25760 missing (87.26%)\n",
      "COLONCAN_A: 25760 missing (87.26%)\n",
      "CERVICAN_A: 27376 missing (92.73%)\n",
      "BREASCAN_A: 25760 missing (87.26%)\n",
      "BRAINCAN_A: 25760 missing (87.26%)\n",
      "BONECAN_A: 25760 missing (87.26%)\n",
      "BLOODCAN_A: 25760 missing (87.26%)\n",
      "BLADDCAN_A: 25760 missing (87.26%)\n",
      "AGE65: 29400 missing (99.59%)\n",
      "MENTHOLC_A: 26922 missing (91.19%)\n",
      "HOUGVASST_A: 21110 missing (71.51%)\n",
      "FDSNEDAYS_A: 29146 missing (98.73%)\n",
      "FDSNOTEAT_A: 27632 missing (93.60%)\n",
      "FDSWEIGHT_A: 25433 missing (86.15%)\n",
      "FDSHUNGRY_A: 25433 missing (86.15%)\n",
      "FDSLESS_A: 25433 missing (86.15%)\n",
      "FDSSKIPDYS_A: 28016 missing (94.90%)\n",
      "FDSSKIP_A: 25433 missing (86.15%)\n",
      "FLUNCH12M1_A: 23434 missing (79.38%)\n",
      "FWIC12M_A: 15914 missing (53.91%)\n",
      "FSNAP30D_A: 26172 missing (88.65%)\n",
      "INCOTHR_A: 1446 missing (4.90%)\n",
      "INCRETIRE_A: 1446 missing (4.90%)\n",
      "INCWELF_A: 1446 missing (4.90%)\n",
      "SSISSDIDSB_A: 27030 missing (91.56%)\n",
      "SSISSDIBTH_A: 27030 missing (91.56%)\n",
      "INCSSISSDI_A: 1446 missing (4.90%)\n",
      "INCSSRR_A: 1446 missing (4.90%)\n",
      "CEVOLUN2_A: 8068 missing (27.33%)\n",
      "EMDWRKCAT1_A: 11722 missing (39.71%)\n",
      "EMDSUPER_A: 11722 missing (39.71%)\n",
      "EMPHEALINS_A: 11722 missing (39.71%)\n",
      "EMPSICKLV_A: 11722 missing (39.71%)\n",
      "EMPWHENWRK_A: 17523 missing (59.36%)\n",
      "EMPWHYNOT_A: 17470 missing (59.18%)\n",
      "EMPNOWRK_A: 16906 missing (57.27%)\n",
      "VACAREEV_A: 27931 missing (94.61%)\n",
      "VAHOSP_A: 27002 missing (91.46%)\n",
      "VADISB_A: 27002 missing (91.46%)\n",
      "COMBAT_A: 27473 missing (93.06%)\n",
      "AFVETTRN_A: 27002 missing (91.46%)\n",
      "EVRMARRIED_A: 14142 missing (47.90%)\n",
      "SPOUSEP_A: 28790 missing (97.52%)\n",
      "SPOUSLIV_A: 16562 missing (56.10%)\n",
      "HRJBEXP4HR_A: 26841 missing (90.92%)\n",
      "HRVLDPROT_A: 25769 missing (87.29%)\n",
      "HRFIREPROT_A: 25922 missing (87.81%)\n",
      "HRFIRE12M_A: 18076 missing (61.23%)\n",
      "HRFIRETOTR_A: 18076 missing (61.23%)\n",
      "HRJOBPROT_A: 26782 missing (90.72%)\n",
      "HRLOUDJB12M_A: 21980 missing (74.45%)\n",
      "HRLOUDJBYR_A: 21980 missing (74.45%)\n",
      "HRTINMEDSP_A: 25350 missing (85.87%)\n",
      "HRTINPROB_A: 25350 missing (85.87%)\n",
      "HRTINLNG_A: 25350 missing (85.87%)\n",
      "BFALLTIMES_A: 24432 missing (82.76%)\n",
      "BALDHP_A: 23330 missing (79.03%)\n",
      "BALDPROB_A: 23330 missing (79.03%)\n",
      "HRAIDAQR_A: 27788 missing (94.13%)\n",
      "HRTESTLAST_A: 14221 missing (48.17%)\n",
      "CBALHDNO_A: 23051 missing (78.08%)\n",
      "CBALHDINJ_A: 1905 missing (6.45%)\n",
      "EARINFECT3_A: 27830 missing (94.27%)\n",
      "HRWHISP_A: 1134 missing (3.84%)\n",
      "AVISSADV_A: 23974 missing (81.21%)\n",
      "AVISDEV_A: 23750 missing (80.45%)\n",
      "AVISREH_A: 23750 missing (80.45%)\n",
      "SMOKELSCUR_A: 26587 missing (90.06%)\n",
      "PIPECUR_A: 25459 missing (86.24%)\n",
      "CIGAR30D_A: 21376 missing (72.41%)\n",
      "CIGARCUR_A: 21218 missing (71.87%)\n",
      "ECIGNOW_A: 24488 missing (82.95%)\n",
      "CIG30D_A: 28768 missing (97.45%)\n",
      "SMK30D_A: 28734 missing (97.33%)\n",
      "CIGNOW_A: 27175 missing (92.05%)\n",
      "SMKNOW_A: 19149 missing (64.86%)\n",
      "ARTHPH_A: 21791 missing (73.81%)\n",
      "ARTHWRK_A: 21791 missing (73.81%)\n",
      "ARTHLMT_A: 21791 missing (73.81%)\n",
      "JNTPN_A: 23773 missing (80.53%)\n",
      "JNTSYMP_A: 21791 missing (73.81%)\n",
      "TBIEVAL_A: 28584 missing (96.82%)\n",
      "TBILEAGUE_A: 29386 missing (99.54%)\n",
      "TBISPORT_A: 28584 missing (96.82%)\n",
      "INJREDUCE_A: 27679 missing (93.76%)\n",
      "INJSTOPCHG_A: 27679 missing (93.76%)\n",
      "INJFUTWRK_A: 29005 missing (98.25%)\n",
      "INJSTITCH_A: 28273 missing (95.77%)\n",
      "INJBONES_A: 28273 missing (95.77%)\n",
      "INJHOSP_A: 29267 missing (99.14%)\n",
      "INJER_A: 28873 missing (97.80%)\n",
      "INJSAWDOC_A: 27562 missing (93.36%)\n",
      "INJCHORES_A: 27562 missing (93.36%)\n",
      "INJMVTYPE5_A: 29380 missing (99.52%)\n",
      "INJMVTYPE4_A: 29380 missing (99.52%)\n",
      "INJMVTYPE3_A: 29380 missing (99.52%)\n",
      "INJMVTYPE2_A: 29380 missing (99.52%)\n",
      "INJMVTYPE1_A: 29380 missing (99.52%)\n",
      "INJMOTOR_A: 27562 missing (93.36%)\n",
      "INJFALLWRK_A: 29496 missing (99.91%)\n",
      "INJFALLHOM_A: 29336 missing (99.37%)\n",
      "INJFALL_A: 27562 missing (93.36%)\n",
      "INJSPORTS_A: 27562 missing (93.36%)\n",
      "INJWORK_A: 28360 missing (96.06%)\n",
      "INJHOME_A: 27562 missing (93.36%)\n",
      "INJLIMIT_A: 26512 missing (89.80%)\n",
      "REPWRKCAUS_A: 28193 missing (95.50%)\n",
      "REPREDUCE_A: 28286 missing (95.81%)\n",
      "REPSTOPCHG_A: 28286 missing (95.81%)\n",
      "REPFUTWRK_A: 29261 missing (99.12%)\n",
      "REPSAWDOC_A: 28193 missing (95.50%)\n",
      "REPLIMIT_A: 26824 missing (90.86%)\n",
      "PAITOOTH3M_A: 9675 missing (32.77%)\n",
      "PAIAPG3M_A: 9675 missing (32.77%)\n",
      "PAIHDFC3M_A: 9675 missing (32.77%)\n",
      "PAILLMB3M_A: 9675 missing (32.77%)\n",
      "PAIULMB3M_A: 9675 missing (32.77%)\n",
      "PAIBACK3M_A: 9675 missing (32.77%)\n",
      "PAIAFFM3M_A: 9675 missing (32.77%)\n",
      "PAIWKLM3M_A: 9675 missing (32.77%)\n",
      "PAIAMNT_A: 9675 missing (32.77%)\n",
      "MHTPYNOW_A: 25666 missing (86.94%)\n",
      "MHRX_A: 5730 missing (19.41%)\n",
      "DEPLEVEL_A: 15421 missing (52.24%)\n",
      "ANXLEVEL_A: 8882 missing (30.09%)\n",
      "WRKHLTHFC_A: 2871 missing (9.72%)\n",
      "LIVEHEP_A: 621 missing (2.10%)\n",
      "SHTHEPB1_A: 4753 missing (16.10%)\n",
      "TDAPPREG_A: 29171 missing (98.81%)\n",
      "SHINGRIXFS1_A: 25472 missing (86.28%)\n",
      "SHINGRIXN3_A: 27980 missing (94.78%)\n",
      "SHINGRIX3_A: 27231 missing (92.24%)\n",
      "SHINGWHEN1_A: 28777 missing (97.48%)\n",
      "SHTSHINGL1_A: 11879 missing (40.24%)\n",
      "SHTPNEUNB_A: 20692 missing (70.09%)\n",
      "SHOTTYPE2_A: 6080 missing (20.59%)\n",
      "CVDVAC1Y1_A: 6129 missing (20.76%)\n",
      "CVDVAC1M1_A: 6080 missing (20.59%)\n",
      "SHTCVD19NM1_A: 5992 missing (20.30%)\n",
      "FLUPREG2_A: 29367 missing (99.47%)\n",
      "FLUPREG_A: 29460 missing (99.79%)\n",
      "SHTFLUY_A: 14478 missing (49.04%)\n",
      "SHTFLUM_A: 14467 missing (49.00%)\n",
      "LIVEBIRTH_A: 22807 missing (77.25%)\n",
      "PREGFLUYR_A: 22953 missing (77.75%)\n",
      "FHCANRISK_A: 16780 missing (56.84%)\n",
      "FHOVCANNUM_A: 28380 missing (96.13%)\n",
      "FHOVCANEV_A: 16780 missing (56.84%)\n",
      "FHBCAN50_A: 25496 missing (86.36%)\n",
      "FHBCANNUM_A: 25493 missing (86.35%)\n",
      "FHBCANEV_A: 16780 missing (56.84%)\n",
      "MRIREA_A: 28113 missing (95.23%)\n",
      "MRIWHEN_A: 28113 missing (95.23%)\n",
      "MRIHAD_A: 15424 missing (52.25%)\n",
      "MAMNOT1_A: 24197 missing (81.96%)\n",
      "MAMREASON_A: 18472 missing (62.57%)\n",
      "MAMWHEN_A: 18472 missing (62.57%)\n",
      "MAMEV_A: 15424 missing (52.25%)\n",
      "HYSTEV2_A: 13463 missing (45.60%)\n",
      "CERVICWHEN_A: 16840 missing (57.04%)\n",
      "CERVICEV1_A: 13463 missing (45.60%)\n",
      "PSA5YR1_A: 25110 missing (85.06%)\n",
      "PSAREASON_A: 24978 missing (84.61%)\n",
      "PSAWHEN_A: 24978 missing (84.61%)\n",
      "PSATEST_A: 20039 missing (67.88%)\n",
      "COLTEST6_A: 28561 missing (96.74%)\n",
      "COLTEST5_A: 28561 missing (96.74%)\n",
      "COLTEST4_A: 28561 missing (96.74%)\n",
      "COLTEST3_A: 28561 missing (96.74%)\n",
      "COLTEST2_A: 28561 missing (96.74%)\n",
      "COLTEST1_A: 28561 missing (96.74%)\n",
      "COLPROB1_A: 21824 missing (73.92%)\n",
      "CGUARDWHE1_A: 28102 missing (95.19%)\n",
      "FITCOLG1_A: 28202 missing (95.53%)\n",
      "COLOGUARD1_A: 8514 missing (28.84%)\n",
      "FITHWHEN1_A: 24916 missing (84.40%)\n",
      "FITHEV1_A: 8514 missing (28.84%)\n",
      "CTCOLWHEN1_A: 28785 missing (97.50%)\n",
      "CTCOLEV1_A: 8514 missing (28.84%)\n",
      "SIGWHEN_A: 28331 missing (95.97%)\n",
      "COLSIGWHEN_A: 29475 missing (99.84%)\n",
      "COLREASON1_A: 16670 missing (56.47%)\n",
      "COLWHEN_A: 16670 missing (56.47%)\n",
      "COLORECTYP_A: 16498 missing (55.88%)\n",
      "COLORECTEV_A: 8514 missing (28.84%)\n",
      "DIBA1CLAST_A: 26228 missing (88.84%)\n",
      "DIBLAST1_A: 3294 missing (11.16%)\n",
      "RXDL12M_A: 8097 missing (27.43%)\n",
      "RXLS12M_A: 8097 missing (27.43%)\n",
      "RXSK12M_A: 8097 missing (27.43%)\n",
      "HITTEST_A: 2616 missing (8.86%)\n",
      "HITCOMM_A: 2616 missing (8.86%)\n",
      "HITLOOK_A: 2616 missing (8.86%)\n",
      "ACCSSHOM_A: 2616 missing (8.86%)\n",
      "USPLKIND_A: 2921 missing (9.89%)\n",
      "WELLVIS_A: 24245 missing (82.13%)\n",
      "WELLNESS_A: 293 missing (0.99%)\n",
      "LCVDACT_A: 28459 missing (96.40%)\n",
      "SYMPNOW1_A: 27124 missing (91.88%)\n",
      "LONGCOVD1_A: 14168 missing (47.99%)\n",
      "PAYNOBLLNW_A: 26559 missing (89.96%)\n",
      "HINOTMYR_A: 28561 missing (96.74%)\n",
      "HINOTYR_A: 1973 missing (6.68%)\n",
      "RSNHIOTH_A: 27533 missing (93.26%)\n",
      "RSNHIWAIT_A: 27533 missing (93.26%)\n",
      "RSNHIMEET_A: 27533 missing (93.26%)\n",
      "RSNHICONF_A: 27533 missing (93.26%)\n",
      "RSNHIELIG_A: 27533 missing (93.26%)\n",
      "RSNHIWANT_A: 27533 missing (93.26%)\n",
      "RSNHICOST_A: 27533 missing (93.26%)\n",
      "HISTOPELIG_A: 28620 missing (96.94%)\n",
      "HISTOPCOST_A: 28620 missing (96.94%)\n",
      "HISTOPAGE_A: 28620 missing (96.94%)\n",
      "HISTOPMISS_A: 28620 missing (96.94%)\n",
      "HISTOPJOB_A: 28620 missing (96.94%)\n",
      "HILASTMY_A: 28993 missing (98.21%)\n",
      "HILAST_A: 27533 missing (93.26%)\n",
      "MILSPC3_A: 27711 missing (93.87%)\n",
      "MILSPC2_A: 27711 missing (93.87%)\n",
      "MILSPC1_A: 28115 missing (95.23%)\n",
      "OGHDHP_A: 29500 missing (99.93%)\n",
      "OGDEDUC_A: 29453 missing (99.77%)\n",
      "OGPREM_A: 29453 missing (99.77%)\n",
      "OGXCHNG_A: 29453 missing (99.77%)\n",
      "OPHDHP_A: 29472 missing (99.83%)\n",
      "OPDEDUC_A: 29355 missing (99.43%)\n",
      "OPPREM_A: 29355 missing (99.43%)\n",
      "OPXCHNG_A: 29355 missing (99.43%)\n",
      "CHHDHP_A: 29521 missing (100.00%)\n",
      "CHDEDUC_A: 29519 missing (99.99%)\n",
      "CHPREM_A: 29519 missing (99.99%)\n",
      "CHXCHNG_A: 29519 missing (99.99%)\n",
      "PRVSCOV2_A: 28998 missing (98.23%)\n",
      "PRVSCOV1_A: 11453 missing (38.79%)\n",
      "PRDNCOV2_A: 28998 missing (98.23%)\n",
      "PRDNCOV1_A: 11453 missing (38.79%)\n",
      "PRRXCOV2_A: 28998 missing (98.23%)\n",
      "PRRXCOV1_A: 11453 missing (38.79%)\n",
      "HSAHRA2_A: 29448 missing (99.75%)\n",
      "HSAHRA1_A: 22905 missing (77.59%)\n",
      "PRHDHP2_A: 29315 missing (99.30%)\n",
      "PRHDHP1_A: 16968 missing (57.48%)\n",
      "PRDEDUC2_A: 28998 missing (98.23%)\n",
      "PRDEDUC1_A: 11453 missing (38.79%)\n",
      "PLN2PAY6_A: 28998 missing (98.23%)\n",
      "PLN2PAY5_A: 28998 missing (98.23%)\n",
      "PLN2PAY4_A: 28998 missing (98.23%)\n",
      "PLN2PAY3_A: 28998 missing (98.23%)\n",
      "PLN2PAY2_A: 28998 missing (98.23%)\n",
      "PLN2PAY1_A: 28998 missing (98.23%)\n",
      "PLN1PAY6_A: 11453 missing (38.79%)\n",
      "PLN1PAY5_A: 11453 missing (38.79%)\n",
      "PLN1PAY4_A: 11453 missing (38.79%)\n",
      "PLN1PAY3_A: 11453 missing (38.79%)\n",
      "PLN1PAY2_A: 11453 missing (38.79%)\n",
      "PLN1PAY1_A: 11453 missing (38.79%)\n",
      "PLNEXCHG2_A: 29387 missing (99.54%)\n",
      "PLNEXCHG1_A: 26079 missing (88.34%)\n",
      "PRPOLH2_A: 29365 missing (99.47%)\n",
      "PRPOLH1_A: 25769 missing (87.29%)\n",
      "PRPLCOV2_A: 29155 missing (98.76%)\n",
      "PRPLCOV1_A: 15861 missing (53.73%)\n",
      "POLHLD2_A: 28998 missing (98.23%)\n",
      "POLHLD1_A: 11453 missing (38.79%)\n",
      "MAHDHP_A: 29388 missing (99.55%)\n",
      "MADEDUC_A: 25664 missing (86.93%)\n",
      "MAPREM_A: 25664 missing (86.93%)\n",
      "MAXCHNG_A: 25664 missing (86.93%)\n",
      "MCPARTD_A: 19472 missing (65.96%)\n",
      "MCVSCOV_A: 24949 missing (84.51%)\n",
      "MCDNCOV_A: 24949 missing (84.51%)\n",
      "MCHMO_A: 19929 missing (67.51%)\n",
      "MCCHOICE_A: 19929 missing (67.51%)\n",
      "MCPART_A: 19472 missing (65.96%)\n",
      "MCAIDPRB_A: 27538 missing (93.28%)\n",
      "MCAREPRB_A: 28285 missing (95.81%)\n",
      "DEVDONSET_A: 24983 missing (84.63%)\n",
      "COGAMTDFF_A: 24031 missing (81.40%)\n",
      "COGFRQDFF_A: 24031 missing (81.40%)\n",
      "COGTYPEDFF_A: 23153 missing (78.43%)\n",
      "EQSTEPS_A: 27482 missing (93.09%)\n",
      "EQWLK13M_A: 27816 missing (94.22%)\n",
      "EQWLK100_A: 27482 missing (93.09%)\n",
      "NOEQSTEPS_A: 26763 missing (90.65%)\n",
      "NOEQWLK13M_A: 27763 missing (94.04%)\n",
      "NOEQWLK100_A: 26763 missing (90.65%)\n",
      "PERASST_A: 26763 missing (90.65%)\n",
      "WCHAIR_A: 26763 missing (90.65%)\n",
      "CANEWLKR_A: 26763 missing (90.65%)\n",
      "STEPS_A: 2759 missing (9.35%)\n",
      "WLK13M_A: 2946 missing (9.98%)\n",
      "WLK100_A: 2759 missing (9.35%)\n",
      "HEARAIDFR_A: 27788 missing (94.13%)\n",
      "PREGNOW_A: 22805 missing (77.25%)\n",
      "VIMLSCA_A: 27368 missing (92.70%)\n",
      "VIMCAEV_A: 15045 missing (50.96%)\n",
      "VIMCSURG_A: 10715 missing (36.29%)\n",
      "VIMLSMD_A: 28744 missing (97.36%)\n",
      "VIMMDEV_A: 10715 missing (36.29%)\n",
      "VIMLSGL_A: 28434 missing (96.31%)\n",
      "VIMLSDR_A: 29152 missing (98.75%)\n",
      "EPIDR_A: 28954 missing (98.08%)\n",
      "EPIMED_A: 28954 missing (98.08%)\n",
      "CFSNOW_A: 29041 missing (98.37%)\n",
      "DIBTYPE_A: 26228 missing (88.84%)\n",
      "DIBINSSTYR_A: 29492 missing (99.90%)\n",
      "DIBINSSTOP_A: 28474 missing (96.45%)\n",
      "DIBINSTIME_A: 28474 missing (96.45%)\n",
      "DIBINS_A: 23194 missing (78.57%)\n",
      "DIBPILL_A: 23194 missing (78.57%)\n",
      "GESDIB_A: 13463 missing (45.60%)\n",
      "ASER12M_A: 25169 missing (85.26%)\n",
      "ASAT12M_A: 25169 missing (85.26%)\n",
      "ASTILL_A: 25169 missing (85.26%)\n",
      "ASPONOWN_A: 14343 missing (48.58%)\n",
      "ASPMEDSTP_A: 27999 missing (94.84%)\n",
      "ASPMEDNOWN_A: 23694 missing (80.26%)\n",
      "ASPMEDEV_A: 8514 missing (28.84%)\n",
      "CHLMED_A: 19918 missing (67.47%)\n",
      "CHL12M_A: 19918 missing (67.47%)\n",
      "HYPMED_A: 18428 missing (62.42%)\n",
      "HYP12M_A: 20023 missing (67.82%)\n",
      "HYPDIF_A: 18428 missing (62.42%)\n",
      "PROXYREL_A: 28985 missing (98.18%)\n",
      "PROXY_A: 28969 missing (98.13%)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values for all columns and display the count and percentage\n",
    "missing_values = df_copy.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df_copy)) * 100\n",
    "\n",
    "# Count columns with missing values\n",
    "missing_columns_count = (df_copy.isnull().sum() > 0).sum()\n",
    "print(f\"Number of columns with missing values: {missing_columns_count}\")\n",
    "\n",
    "\n",
    "# Filter only columns with missing values\n",
    "missing_data = missing_values[missing_values > 0]\n",
    "\n",
    "# Print missing values and percentages\n",
    "print(\"Columns with Missing Values:\")\n",
    "for col in missing_data.index:\n",
    "    print(f\"{col}: {missing_data[col]} missing ({missing_percentage[col]:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns after dropping: 294\n"
     ]
    }
   ],
   "source": [
    "# Recalculate missing percentages based on df_copy\n",
    "missing_percent = (df_copy.isnull().sum() / len(df_copy)) * 100  \n",
    "\n",
    "# Select only columns where missing percentage is less than 50%\n",
    "df_copy = df_copy.loc[:, missing_percent < 50]\n",
    "\n",
    "print(f\"Remaining columns after dropping: {df_copy.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values after dropping columns: 733072\n"
     ]
    }
   ],
   "source": [
    "# Check how many missing values remain\n",
    "total_missing = df_copy.isnull().sum().sum()\n",
    "print(f\"Total missing values after dropping columns: {total_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 29522\n",
      "Rows with at least 80% valid data: 29225\n",
      "Percentage of rows with ≥80% valid data: 98.99%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the threshold (50% of total columns)\n",
    "valid_data_threshold = int(df_copy.shape[1] * 0.8)\n",
    "\n",
    "# Count rows that have at least 50% valid (non-missing) data\n",
    "rows_with_80_valid = (df_copy.notnull().sum(axis=1) >= valid_data_threshold).sum()\n",
    "\n",
    "# Print results\n",
    "print(f\"Total rows: {df_copy.shape[0]}\")\n",
    "print(f\"Rows with at least 80% valid data: {rows_with_80_valid}\")\n",
    "print(f\"Percentage of rows with ≥80% valid data: {(rows_with_80_valid / df_copy.shape[0]) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New total rows after dropping low-validity rows: 29225\n"
     ]
    }
   ],
   "source": [
    "df_copy = df_copy.dropna(thresh=int(df_copy.shape[1] * 0.8))\n",
    "print(f\"New total rows after dropping low-validity rows: {df_copy.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values after row filtering: 713714\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total missing values after row filtering: {df_copy.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop single categorical column for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Set (X): (29225, 292)\n",
      "Target (y): (29225,)\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable (Life Satisfaction)\n",
    "y = df_copy[\"LSATIS4_A\"]  # Target variable\n",
    "X = df_copy.drop(columns=[\"LSATIS4_A\"])  # Features (everything except target)\n",
    "\n",
    "# Confirm separation\n",
    "print(f\"Feature Set (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20457, 292), X_val shape: (8768, 292)\n",
      "y_train shape: (20457,), y_val shape: (8768,)\n"
     ]
    }
   ],
   "source": [
    "#Train/Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.3, \n",
    "                                                  random_state = 0, \n",
    "                                                  stratify = y, \n",
    "                                                  shuffle = True)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, X_val shape: {X_val.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 New training set size: 20408\n",
      "🔹 New validation set size: 8747\n"
     ]
    }
   ],
   "source": [
    "# Keep only valid target labels (1, 2, 3, 4)\n",
    "valid_classes = [1, 2, 3, 4]\n",
    "mask = y_train.isin(valid_classes)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "mask_val = y_val.isin(valid_classes)\n",
    "X_val = X_val[mask_val]\n",
    "y_val = y_val[mask_val]\n",
    "\n",
    "print(f\"🔹 New training set size: {X_train.shape[0]}\")\n",
    "print(f\"🔹 New validation set size: {X_val.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X_train after imputation: 0\n",
      "Missing values in X_val after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Replace NaNs with median values\n",
    "\n",
    "# Fill missing values in X_train using median\n",
    "X_train.fillna(X_train.median(), inplace=True)\n",
    "\n",
    "# Apply same imputation to X_val using X_train's median values\n",
    "X_val.fillna(X_train.median(), inplace=True)\n",
    "\n",
    "# Confirm no missing values remain\n",
    "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_val after imputation: {X_val.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spearman Correlation\n",
    "-Randomly select which feature to drop from two highly-correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 32 highly correlated features.\n",
      "New X_train shape: (20408, 260), New X_val shape: (8747, 260)\n"
     ]
    }
   ],
   "source": [
    "# Compute correlation matrix\n",
    "corr_matrix = X_train.corr(method='spearman').abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find columns with correlation > 0.9\n",
    "high_corr_features = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "\n",
    "# Drop highly correlated features from both train and validation sets\n",
    "X_train = X_train.drop(columns=high_corr_features)\n",
    "X_val = X_val.drop(columns=high_corr_features)\n",
    "\n",
    "print(f\"Dropped {len(high_corr_features)} highly correlated features.\")\n",
    "print(f\"New X_train shape: {X_train.shape}, New X_val shape: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE that selects the top 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2798319331.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[82], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''# Train RFE with Random Forest\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# Train RFE with Random Forest\n",
    "rfe_selector = RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=0), n_features_to_select=30)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "\n",
    "# Store RFE feature rankings\n",
    "rfe_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"RFE_Rank\": rfe_selector.ranking_  # Lower rank = more important\n",
    "})\n",
    "\n",
    "# Sort by rank (lower is better)\n",
    "rfe_ranking = rfe_ranking.sort_values(by=\"RFE_Rank\", ascending=True)\n",
    "\n",
    "# Store the top 30 RFE features\n",
    "selected_features_rfe = rfe_ranking[\"Feature\"].head(30).tolist()\n",
    "\n",
    "# Print the top 30 RFE features\n",
    "print(\"\\n🔹 Top 30 Most Important Features (RFE):\")\n",
    "print(rfe_ranking.head(30))\n",
    "\n",
    "print(f\"\\n✅ Selected {len(selected_features_rfe)} features using RFE.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFECV to determine optimal number of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Optimal number of features selected by RFECV: 154\n",
      "🔹 Selected Features: ['URBRRL', 'RATCAT_A', 'IMPINCFLG_A', 'PPSU', 'PSTRAT', 'HISPALLP_A', 'RACEALLP_A', 'DISAB3_A', 'LEGMSTAT_A', 'MARSTAT_A', 'PCNTADWFP1_A', 'FDSCAT4_A', 'EMPDYSMSS3_A', 'EMPWRKLSW1_A', 'EMPWKHRS3_A', 'EMDOCCUPN2_A', 'EMDINDSTN2_A', 'SMKECIGST_A', 'SMKCIGST_A', 'BMICAT_A', 'WEIGHTLBTC_A', 'HEIGHTTC_A', 'URGNT12MTC_A', 'EMERG12MTC_A', 'PCNT18UPTC', 'PCNTLT18TC', 'PHQ2SCREEN_A', 'GAD2SCREEN_A', 'COVER_A', 'PLNWRKR1_A', 'PRIVATE_A', 'EXCHPR1_A', 'EDUCP_A', 'NUMCAN_A', 'HISDETP_A', 'REGION', 'INTV_QRT', 'SEX_A', 'AGEP_A', 'CEVOTELC_A', 'HOUSECOST_A', 'HOUTENURE_A', 'HOUYRSLIV_A', 'FDSBALANCE_A', 'INCRETIRE_A', 'INCSSISSDI_A', 'INCSSRR_A', 'INCINTER_A', 'INCWRKO_A', 'CEVOLUN1_A', 'EMDWRKCAT1_A', 'EMPSICKLV_A', 'HRFIREEV_A', 'HRLOUDJOB_A', 'HRTINNITUS_A', 'BALDIZZ_A', 'HRTESTLAST_A', 'HRTEST_A', 'CBALHDINJ_A', 'HRWHISP_A', 'AHEARST1_A', 'VIMDRIVE_A', 'VIMREAD_A', 'AVISEXAM_A', 'CIGAREV_A', 'PAITOOTH3M_A', 'PAIAPG3M_A', 'PAIHDFC3M_A', 'PAILLMB3M_A', 'PAIULMB3M_A', 'PAIBACK3M_A', 'PAIAFFM3M_A', 'PAIWKLM3M_A', 'PAIAMNT_A', 'PAIFRQ3M_A', 'VIGIL4_A', 'VIGIL3_A', 'VIGIL2_A', 'VIGIL1_A', 'DISCRIM5_A', 'DISCRIM4_A', 'DISCRIM3_A', 'DISCRIM2_A', 'DISCRIM1_A', 'PHQ44_A', 'PHQ43_A', 'PHQ42_A', 'PHQ41_A', 'DEPFREQ_A', 'ANXLEVEL_A', 'ANXFREQ_A', 'EYEEX12M_A', 'TRAVEL_A', 'SHTHEPB1_A', 'SHTSHINGL1_A', 'SHTPNUEV_A', 'SHOTTYPE2_A', 'CVDVAC1Y1_A', 'CVDVAC1M1_A', 'SHTCVD19NM1_A', 'SHTCVD191_A', 'SHTFLUY_A', 'SHTFLUM_A', 'SHTFLU12M_A', 'FHCANEV_A', 'FITHEV1_A', 'COLORECTEV_A', 'DIBLAST1_A', 'CHOLLAST_A', 'BPLAST_A', 'HITTEST_A', 'HITCOMM_A', 'HITLOOK_A', 'VIRAPP12M_A', 'MEDNG12M_A', 'USPLKIND_A', 'WELLNESS_A', 'LASTDR_A', 'DENNG12M_A', 'DENDL12M_A', 'DENPREV_A', 'LONGCOVD1_A', 'EVERCOVD_A', 'PAYWORRY_A', 'PAYBLL12M_A', 'PRVSCOV1_A', 'PRDNCOV1_A', 'PRDEDUC1_A', 'PLN1PAY2_A', 'SINCOVRX_A', 'SINCOVVS_A', 'SINCOVDE_A', 'SOCWRKLIM_A', 'SOCSCLPAR_A', 'SOCERRNDS_A', 'UPPOBJCT_A', 'UPPRAISE_A', 'UPPSLFCR_A', 'COGMEMDFF_A', 'STEPS_A', 'WLK13M_A', 'WLK100_A', 'DIFF_A', 'HEARINGDF_A', 'VISIONDF_A', 'WEARGLSS_A', 'DEPEV_A', 'ANXEV_A', 'ARTHEV_A', 'PREDIB_A', 'CHLEV_A', 'HYPEV_A', 'PHSTAT_A', 'WTFA_A']\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=0, class_weight=\"balanced\")\n",
    "\n",
    "# 🔹 Use RFECV to determine the optimal number of features\n",
    "rfecv = RFECV(estimator=rf_classifier, step=1, cv=StratifiedKFold(5), scoring='accuracy', n_jobs=-1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# 🔹 Get the optimal number of features\n",
    "optimal_features = X_train.columns[rfecv.support_]  # Boolean mask of selected features\n",
    "num_selected_features = sum(rfecv.support_)  # Count selected features\n",
    "\n",
    "# 🔹 Print results\n",
    "print(f\"✅ Optimal number of features selected by RFECV: {num_selected_features}\")\n",
    "print(f\"🔹 Selected Features: {list(optimal_features)}\")\n",
    "\n",
    "# 🔹 Filter dataset to keep only selected features\n",
    "X_train_selected = X_train[optimal_features]\n",
    "X_val_selected = X_val[optimal_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE with rankings for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Full RFE Feature Rankings:\n",
      "           Feature  RFE_Rank\n",
      "259         WTFA_A         1\n",
      "26    WEIGHTLBTC_A         2\n",
      "5             PPSU         3\n",
      "55          AGEP_A         4\n",
      "6           PSTRAT         5\n",
      "27      HEIGHTTC_A         6\n",
      "254       PHSTAT_A         7\n",
      "150    CVDVAC1M1_A         8\n",
      "134      DEPFREQ_A         9\n",
      "1         RATCAT_A        10\n",
      "21    EMDOCCUPN2_A        11\n",
      "47         EDUCP_A        12\n",
      "22    EMDINDSTN2_A        13\n",
      "137      ANXFREQ_A        14\n",
      "13       MARSTAT_A        15\n",
      "99      AVISEXAM_A        16\n",
      "62     HOUYRSLIV_A        17\n",
      "151  SHTCVD19NM1_A        18\n",
      "20     EMPWKHRS3_A        19\n",
      "52        INTV_QRT        20\n",
      "129        PHQ41_A        21\n",
      "154      SHTFLUM_A        22\n",
      "96      AHEARST1_A        23\n",
      "0           URBRRL        24\n",
      "188      DENPREV_A        25\n",
      "125     DISCRIM1_A        26\n",
      "51          REGION        27\n",
      "128        PHQ42_A        28\n",
      "91    HRTESTLAST_A        29\n",
      "116     PAIFRQ3M_A        30\n"
     ]
    }
   ],
   "source": [
    "# Train RFE but keep rankings for ALL features\n",
    "rfe_selector = RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=0), n_features_to_select=1, step=1)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "\n",
    "# Get rankings for all features\n",
    "rfe_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"RFE_Rank\": rfe_selector.ranking_  # Lower rank = more important\n",
    "})\n",
    "\n",
    "# 🔹 Convert RFE rankings to a dictionary\n",
    "rfe_ranking_dict = rfe_ranking.set_index(\"Feature\")[\"RFE_Rank\"].to_dict()\n",
    "\n",
    "# Sort features by ranking\n",
    "rfe_ranking = rfe_ranking.sort_values(by=\"RFE_Rank\", ascending=True)\n",
    "\n",
    "# Print rankings (top 30)\n",
    "print(\"\\n🔹 Full RFE Feature Rankings:\")\n",
    "print(rfe_ranking.head(30))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RATCAT_A', 'PPSU', 'PSTRAT', 'MARSTAT_A', 'EMDOCCUPN2_A',\n",
      "       'EMDINDSTN2_A', 'WEIGHTLBTC_A', 'HEIGHTTC_A', 'EDUCP_A', 'AGEP_A',\n",
      "       'AVISEXAM_A', 'DISCRIM2_A', 'PHQ42_A', 'DEPFREQ_A', 'ANXFREQ_A',\n",
      "       'CVDVAC1M1_A', 'SHTCVD19NM1_A', 'SHTFLUM_A', 'PHSTAT_A', 'WTFA_A'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stores top 30 most important lasso features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Top 30 Most Important Features (LASSO):\n",
      "          Feature  Lasso_Coeff  Abs_Lasso_Coeff\n",
      "254      PHSTAT_A     0.151777         0.151777\n",
      "134     DEPFREQ_A    -0.088054         0.088054\n",
      "128       PHQ42_A     0.054759         0.054759\n",
      "137     ANXFREQ_A    -0.046543         0.046543\n",
      "13      MARSTAT_A     0.046137         0.046137\n",
      "129       PHQ41_A     0.039336         0.039336\n",
      "73     CEVOLUN1_A     0.032701         0.032701\n",
      "32   PHQ2SCREEN_A    -0.032232         0.032232\n",
      "1        RATCAT_A    -0.025629         0.025629\n",
      "191    PAYWORRY_A    -0.024567         0.024567\n",
      "30     PCNT18UPTC    -0.022252         0.022252\n",
      "63   FDSBALANCE_A    -0.019823         0.019823\n",
      "96     AHEARST1_A     0.018884         0.018884\n",
      "54          SEX_A    -0.018648         0.018648\n",
      "125    DISCRIM1_A    -0.017858         0.017858\n",
      "19   EMPWRKLSW1_A    -0.017215         0.017215\n",
      "209   SOCSCLPAR_A     0.016341         0.016341\n",
      "59     TRANSPOR_A    -0.016050         0.016050\n",
      "180    MEDDL12M_A    -0.015133         0.015133\n",
      "188     DENPREV_A     0.013678         0.013678\n",
      "57     CEVOTELC_A     0.013478         0.013478\n",
      "77    EMPSICKLV_A     0.012649         0.012649\n",
      "184    WELLNESS_A     0.011247         0.011247\n",
      "214   COGMEMDFF_A     0.011236         0.011236\n",
      "7      HISPALLP_A     0.011234         0.011234\n",
      "135    ANXLEVEL_A     0.010933         0.010933\n",
      "23    SMKECIGST_A    -0.010618         0.010618\n",
      "62    HOUYRSLIV_A     0.010579         0.010579\n",
      "174     HITCOMM_A     0.009271         0.009271\n",
      "29   EMERG12MTC_A    -0.009204         0.009204\n",
      "\n",
      "✅ Selected 30 features using LASSO.\n"
     ]
    }
   ],
   "source": [
    "# Standardize Features (LASSO is sensitive to scale)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 🔹 Train LASSO with Cross-Validation\n",
    "lasso = LassoCV(cv=5, random_state=0)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Store LASSO feature coefficients\n",
    "lasso_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Lasso_Coeff\": lasso.coef_\n",
    "})\n",
    "\n",
    "# Convert Lasso Coefficients to absolute values\n",
    "lasso_ranking[\"Abs_Lasso_Coeff\"] = np.abs(lasso_ranking[\"Lasso_Coeff\"])\n",
    "\n",
    "# Sort by absolute LASSO coefficient (higher is better)\n",
    "lasso_ranking = lasso_ranking.sort_values(by=\"Abs_Lasso_Coeff\", ascending=False)\n",
    "\n",
    "# Store the top 30 LASSO features\n",
    "selected_features_lasso = lasso_ranking[\"Feature\"].head(30).tolist()\n",
    "\n",
    "# 🔹 Print the top 30 LASSO features\n",
    "print(\"\\n🔹 Top 30 Most Important Features (LASSO):\")\n",
    "print(lasso_ranking.head(30))\n",
    "\n",
    "print(f\"\\n✅ Selected {len(selected_features_lasso)} features using LASSO.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso that ranks all important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Ranked Features by Importance (LASSO):\n",
      "         Feature  Abs_Lasso_Coeff\n",
      "254     PHSTAT_A         0.151777\n",
      "134    DEPFREQ_A         0.088054\n",
      "128      PHQ42_A         0.054759\n",
      "137    ANXFREQ_A         0.046543\n",
      "13     MARSTAT_A         0.046137\n",
      "..           ...              ...\n",
      "156    FHCANEV_A         0.000000\n",
      "89    BFALL12M_A         0.000000\n",
      "50     HISDETP_A         0.000000\n",
      "152  SHTCVD191_A         0.000000\n",
      "259       WTFA_A         0.000000\n",
      "\n",
      "[260 rows x 2 columns]\n",
      "\n",
      "✅ Selected 131 important features using LASSO.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 🔹 Standardize Features (LASSO is sensitive to scale)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 🔹 Train LASSO with Cross-Validation\n",
    "lasso = LassoCV(cv=5, random_state=0)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 🔹 Store LASSO feature coefficients\n",
    "lasso_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Lasso_Coeff\": lasso.coef_\n",
    "})\n",
    "\n",
    "# 🔹 Convert Lasso Coefficients to absolute values\n",
    "lasso_ranking[\"Abs_Lasso_Coeff\"] = np.abs(lasso_ranking[\"Lasso_Coeff\"])\n",
    "\n",
    "# 🔹 Create LASSO coefficient dictionary\n",
    "lasso_coeff_dict = lasso_ranking.set_index(\"Feature\")[\"Lasso_Coeff\"].to_dict()\n",
    "\n",
    "# 🔹 Sort ALL features by absolute LASSO coefficient (higher = better)\n",
    "lasso_ranking = lasso_ranking.sort_values(by=\"Abs_Lasso_Coeff\", ascending=False)\n",
    "\n",
    "# 🔹 Store ALL important features (i.e., non-zero coefficients)\n",
    "selected_features_lasso = lasso_ranking[lasso_ranking[\"Abs_Lasso_Coeff\"] > 0][\"Feature\"].tolist()\n",
    "\n",
    "# 🔹 Print the full feature importance ranking\n",
    "print(\"\\n🔹 Ranked Features by Importance (LASSO):\")\n",
    "print(lasso_ranking[[\"Feature\", \"Abs_Lasso_Coeff\"]])\n",
    "\n",
    "print(f\"\\n✅ Selected {len(selected_features_lasso)} important features using LASSO.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unweighted combination of lasso and RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Final Top 30 Features (Based on RFE & LASSO):\n",
      "           Feature  RFE_Score  Lasso_Score  Final_Score\n",
      "1         RATCAT_A          1            1            2\n",
      "62     HOUYRSLIV_A          1            1            2\n",
      "128        PHQ42_A          1            1            2\n",
      "129        PHQ41_A          1            1            2\n",
      "96      AHEARST1_A          1            1            2\n",
      "134      DEPFREQ_A          1            1            2\n",
      "137      ANXFREQ_A          1            1            2\n",
      "13       MARSTAT_A          1            1            2\n",
      "125     DISCRIM1_A          1            1            2\n",
      "188      DENPREV_A          1            1            2\n",
      "254       PHSTAT_A          1            1            2\n",
      "59      TRANSPOR_A          0            1            1\n",
      "99      AVISEXAM_A          1            0            1\n",
      "73      CEVOLUN1_A          0            1            1\n",
      "77     EMPSICKLV_A          0            1            1\n",
      "57      CEVOTELC_A          0            1            1\n",
      "91    HRTESTLAST_A          1            0            1\n",
      "55          AGEP_A          1            0            1\n",
      "54           SEX_A          0            1            1\n",
      "52        INTV_QRT          1            0            1\n",
      "63    FDSBALANCE_A          0            1            1\n",
      "0           URBRRL          1            0            1\n",
      "116     PAIFRQ3M_A          1            0            1\n",
      "47         EDUCP_A          1            0            1\n",
      "135     ANXLEVEL_A          0            1            1\n",
      "150    CVDVAC1M1_A          1            0            1\n",
      "151  SHTCVD19NM1_A          1            0            1\n",
      "154      SHTFLUM_A          1            0            1\n",
      "174      HITCOMM_A          0            1            1\n",
      "180     MEDDL12M_A          0            1            1\n",
      "\n",
      "✅ Final selection: 30 most important features.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Combine RFE and LASSO features into a DataFrame\n",
    "feature_ranking = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns\n",
    "})\n",
    "\n",
    "# 🔹 Assign scores based on selection:\n",
    "feature_ranking[\"RFE_Score\"] = feature_ranking[\"Feature\"].apply(lambda x: 1 if x in selected_features_rfe else 0)\n",
    "feature_ranking[\"Lasso_Score\"] = feature_ranking[\"Feature\"].apply(lambda x: 1 if x in selected_features_lasso else 0)\n",
    "\n",
    "# 🔹 Compute final importance score (sum of both methods)\n",
    "feature_ranking[\"Final_Score\"] = feature_ranking[\"RFE_Score\"] + feature_ranking[\"Lasso_Score\"]\n",
    "\n",
    "# Sort by final score (higher score = more important)\n",
    "feature_ranking = feature_ranking.sort_values(by=\"Final_Score\", ascending=False)\n",
    "\n",
    "# Select the top 30 final features\n",
    "selected_features_final = feature_ranking[\"Feature\"].head(30).tolist()\n",
    "\n",
    "# 🔹 Print the top 30 final selected features\n",
    "print(\"\\n🔹 Final Top 30 Features (Based on RFE & LASSO):\")\n",
    "print(feature_ranking.head(30))\n",
    "\n",
    "print(f\"\\n✅ Final selection: {len(selected_features_final)} most important features.\")\n",
    "\n",
    "# 🔹 Filter dataset to keep only selected features\n",
    "X_train_selected = X_train[selected_features_final]\n",
    "X_val_selected = X_val[selected_features_final]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted combination of lasso and RFE\n",
    "-Requires RFE to rank ALL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Final Top 30 Features (Weighted Ranking):\n",
      "           Feature  Final_Score\n",
      "254       PHSTAT_A     0.988417\n",
      "134      DEPFREQ_A     0.774633\n",
      "128        PHQ42_A     0.628268\n",
      "137      ANXFREQ_A     0.628231\n",
      "13       MARSTAT_A     0.624962\n",
      "129        PHQ41_A     0.590976\n",
      "1         RATCAT_A     0.567056\n",
      "96      AHEARST1_A     0.519740\n",
      "191     PAYWORRY_A     0.515293\n",
      "125     DISCRIM1_A     0.510567\n",
      "62     HOUYRSLIV_A     0.503962\n",
      "21    EMDOCCUPN2_A     0.501246\n",
      "5             PPSU     0.500797\n",
      "259         WTFA_A     0.500000\n",
      "26    WEIGHTLBTC_A     0.499595\n",
      "188      DENPREV_A     0.498729\n",
      "55          AGEP_A     0.494208\n",
      "6           PSTRAT     0.492278\n",
      "27      HEIGHTTC_A     0.490347\n",
      "150    CVDVAC1M1_A     0.487944\n",
      "73      CEVOLUN1_A     0.484176\n",
      "47         EDUCP_A     0.482090\n",
      "0           URBRRL     0.481187\n",
      "22    EMDINDSTN2_A     0.476834\n",
      "30      PCNT18UPTC     0.474850\n",
      "154      SHTFLUM_A     0.473560\n",
      "20     EMPWKHRS3_A     0.473197\n",
      "151  SHTCVD19NM1_A     0.472533\n",
      "99      AVISEXAM_A     0.471042\n",
      "7       HISPALLP_A     0.469439\n",
      "\n",
      "✅ Final selection: 30 most important features.\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame to store feature rankings\n",
    "feature_ranking = pd.DataFrame({\"Feature\": X_train.columns})\n",
    "\n",
    "# 🔹 Assign scores based on rankings & importance:\n",
    "feature_ranking[\"RFE_Rank\"] = feature_ranking[\"Feature\"].map(lambda x: rfe_ranking_dict.get(x, np.nan))  # Lower is better\n",
    "feature_ranking[\"Lasso_Coeff\"] = feature_ranking[\"Feature\"].map(lambda x: lasso_coeff_dict.get(x, 0))  # Higher is better\n",
    "\n",
    "# 🔹 Normalize scores for fair comparison\n",
    "feature_ranking[\"Norm_RFE\"] = (feature_ranking[\"RFE_Rank\"].max() - feature_ranking[\"RFE_Rank\"]) / (feature_ranking[\"RFE_Rank\"].max() - feature_ranking[\"RFE_Rank\"].min())  # Invert so higher = better\n",
    "feature_ranking[\"Norm_Lasso\"] = np.abs(feature_ranking[\"Lasso_Coeff\"]) / np.abs(feature_ranking[\"Lasso_Coeff\"]).max()  # Higher = better\n",
    "\n",
    "# 🔹 Compute final weighted importance score\n",
    "feature_ranking[\"Final_Score\"] = (\n",
    "    feature_ranking[\"Norm_RFE\"] * 0.5 +  # RFE importance (50%)\n",
    "    feature_ranking[\"Norm_Lasso\"] * 0.5  # LASSO importance (50%)\n",
    ")\n",
    "\n",
    "# 🔹 Sort by final importance score\n",
    "feature_ranking = feature_ranking.sort_values(by=\"Final_Score\", ascending=False)\n",
    "\n",
    "# 🔹 Select top 30 most important features\n",
    "selected_features_final = feature_ranking[\"Feature\"].head(30).tolist()\n",
    "\n",
    "# 🔹 Print the final ranked top 30 features\n",
    "print(\"\\n🔹 Final Top 30 Features (Weighted Ranking):\")\n",
    "print(feature_ranking[[\"Feature\", \"Final_Score\"]].head(30))\n",
    "\n",
    "print(f\"\\n✅ Final selection: {len(selected_features_final)} most important features.\")\n",
    "\n",
    "# 🔹 Filter dataset to keep only selected features\n",
    "X_train_selected = X_train[selected_features_final]\n",
    "X_val_selected = X_val[selected_features_final]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apparently this is the final optimized RFE combined with lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Run RFECV to Select Optimal Features\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=0, class_weight=\"balanced\")\n",
    "\n",
    "rfecv = RFECV(estimator=rf_classifier, step=1, cv=StratifiedKFold(5), scoring='accuracy', n_jobs=-1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# Get RFECV-selected features\n",
    "rfecv_features = set(X_train.columns[rfecv.support_])\n",
    "num_rfecv_features = len(rfecv_features)\n",
    "print(f\"✅ RFECV selected {num_rfecv_features} features.\")\n",
    "\n",
    "# 2️⃣ Run LASSO to Identify Important Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "lasso = LassoCV(cv=5, random_state=0)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get LASSO-selected features (non-zero coefficients)\n",
    "lasso_features = set(X_train.columns[lasso.coef_ != 0])\n",
    "num_lasso_features = len(lasso_features)\n",
    "print(f\"✅ LASSO selected {num_lasso_features} features.\")\n",
    "\n",
    "# Combine RFECV + LASSO Features\n",
    "final_features = rfecv_features.union(lasso_features)  # Merge both sets\n",
    "num_final_features = len(final_features)\n",
    "\n",
    "# Print the final feature selection results\n",
    "print(f\"\\n🔹 Final feature set includes {num_final_features} features (RFECV + LASSO).\")\n",
    "print(f\"📝 Features Selected: {list(final_features)}\")\n",
    "\n",
    "# Filter Dataset to Keep Only Selected Features\n",
    "X_train_selected = X_train[list(final_features)]\n",
    "X_val_selected = X_val[list(final_features)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions for both training and validation sets\n",
    "lr_train_preds = model.predict(X_train_selected)\n",
    "lr_val_preds = model.predict(X_val_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Training Set Metrics:\n",
      "  - Accuracy: 0.5160\n",
      "  - Precision: 0.4706\n",
      "  - Recall: 0.5160\n",
      "  - F1-score: 0.3733\n",
      "\n",
      "🔹 Validation Set Metrics:\n",
      "  - Accuracy: 0.5129\n",
      "  - Precision: 0.4454\n",
      "  - Recall: 0.5129\n",
      "  - F1-score: 0.3717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate classification performance\n",
    "def evaluate_classification(y_true, y_pred, dataset=\"Validation\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"🔹 {dataset} Set Metrics:\")\n",
    "    print(f\"  - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  - Precision: {precision:.4f}\")\n",
    "    print(f\"  - Recall: {recall:.4f}\")\n",
    "    print(f\"  - F1-score: {f1:.4f}\\n\")\n",
    "\n",
    "# Evaluate on Training Set\n",
    "evaluate_classification(y_train, lr_train_preds, dataset=\"Training\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "evaluate_classification(y_val, lr_val_preds, dataset=\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get feature importance from model coefficients (for Linear Regression)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_selected\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCoefficient\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Sort by absolute coefficient value (most important first)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m feature_importance[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbs_Coefficient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m feature_importance[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficient\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mabs()\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\sacar\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# Get feature importance from model coefficients (for Linear Regression)\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X_train_selected.columns,\n",
    "    \"Coefficient\": model.coef_\n",
    "})\n",
    "\n",
    "# Sort by absolute coefficient value (most important first)\n",
    "feature_importance[\"Abs_Coefficient\"] = feature_importance[\"Coefficient\"].abs()\n",
    "feature_importance = feature_importance.sort_values(by=\"Abs_Coefficient\", ascending=False)\n",
    "\n",
    "# Display the top 20 most important features\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=200,  # More trees\n",
    "    max_depth=10,  # Prevent overfitting\n",
    "    min_samples_split=5,  # Require more samples to split\n",
    "    min_samples_leaf=2,  # Require more samples per leaf\n",
    "    class_weight='balanced',  # Adjust for imbalanced data\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Train classifier\n",
    "rf_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_train_preds = rf_classifier.predict(X_train_selected)\n",
    "rf_val_preds = rf_classifier.predict(X_val_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Training Set Metrics:\n",
      "  - Accuracy: 0.7124\n",
      "  - Precision: 0.7234\n",
      "  - Recall: 0.7124\n",
      "  - F1-score: 0.7131\n",
      "\n",
      "🔹 Validation Set Metrics:\n",
      "  - Accuracy: 0.6377\n",
      "  - Precision: 0.6469\n",
      "  - Recall: 0.6377\n",
      "  - F1-score: 0.6400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to evaluate classification performance\n",
    "def evaluate_classification(y_true, y_pred, dataset=\"Validation\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"🔹 {dataset} Set Metrics:\")\n",
    "    print(f\"  - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  - Precision: {precision:.4f}\")\n",
    "    print(f\"  - Recall: {recall:.4f}\")\n",
    "    print(f\"  - F1-score: {f1:.4f}\\n\")\n",
    "\n",
    "# Evaluate on Training Set\n",
    "evaluate_classification(y_train, rf_train_preds, dataset=\"Training\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "evaluate_classification(y_val, rf_val_preds, dataset=\"Validation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current High-Score: F1 = .6413 using optimum # from just RFECV\n",
    "\n",
    "Tried:\n",
    "All features\n",
    "Top 30 RFE + Lasso Unweighted\n",
    "Just RFECV\n",
    "RFE (all features) + lasso (all features) weighted\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
